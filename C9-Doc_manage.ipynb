{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:small; color:gray;\"> Author: 鄭永誠, Year: 2024 </p>\n",
    "\n",
    "# 一些文檔處理工具基於 llama_index\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基礎改念 (複習):\n",
    "- **chunk** ➡️ 分塊，當資料量太大時，我們會將其切成一個一個分塊(chunks)\n",
    "\n",
    "- **parse / parsing** ➡️ 把句子解析、轉換成更好理解的格式，像是語法結構調整、識別問題 、抽取訊息\n",
    "\n",
    "- **token / tokenization** ➡️ token是LLM在處理文字時的最小單位，可以理解就像是一個個單字，留意不同LLM會用[不同詞彙表](https://huggingface.co/docs/transformers/en/tokenizer_summary)切token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Name: llama-index\n",
      "Version: 0.10.64\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: Jerry Liu\n",
      "Author-email: jerry@llamaindex.ai\n",
      "License: MIT\n",
      "Location: c:\\Users\\PipiHi\\Desktop\\KM\\llm-course-zh\\.venv\\Lib\\site-packages\n",
      "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-legacy, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 安裝llamaindex \"\"\"\n",
    "# %pip uninstall llama_index -q\n",
    "%pip install llama-index -q\n",
    "%pip show llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-core -q\n",
    "%pip install llama-index-llms-openai -q\n",
    "%pip install llama-index-llms-replicate -q\n",
    "%pip install llama-index-embeddings-huggingface -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_example = [\n",
    "    {\n",
    "        'title': 'Alice', \n",
    "        'content': 'Alice is very adaptable and can handle unexpected challenges with ease.', \n",
    "        'job': ['Engineer', 'Designer']\n",
    "    }, \n",
    "    {\n",
    "        'title': 'Bob',\n",
    "        'content': 'Bob is a natural leader with strong communication skills.',\n",
    "        'job': ['Teacher', 'Writer']\n",
    "    }, \n",
    "    {\n",
    "        'title': 'Charlie',\n",
    "        'content': 'Charlie is a charismatic individual who easily connects with others', \n",
    "        'job': ['Doctor', 'Researcher']\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## SentenceSplitter - chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index\n",
      "Version: 0.10.64\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: Jerry Liu\n",
      "Author-email: jerry@llamaindex.ai\n",
      "License: MIT\n",
      "Location: c:\\Users\\PipiHi\\Desktop\\KM\\llm-course-zh\\.venv\\Lib\\site-packages\n",
      "Requires: llama-index-agent-openai, llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-legacy, llama-index-llms-openai, llama-index-multi-modal-llms-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index-readers-file, llama-index-readers-llama-parse\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原本文檔：\n",
      "義大利麵應拌什麼好?<回答>我個人認為義大利麵就應該拌42號混泥土，因為這個螺絲釘的長度很容易直接影\n",
      "響到挖掘機的扭矩。你往裡砸的時候，一瞬間他就會產生大量的高能蛋白，俗稱UFO，會嚴重影響經濟的發展，\n",
      "以至於對整個太平洋，和充電器的核污染。再或者說透過這勾股定理很容易推斷出人工飼養的東條英機，他是可以\n",
      "捕獲野生的三角函數，所以說不管這秦始皇的切面是否具有放射性，川普的N次方是否有沈澱物，都不會影響到沃\n",
      "爾瑪跟維爾康在南極匯合。\n",
      "\n",
      "分割後的文檔：\n",
      "[part_0]：義大利麵應拌什麼好?<回答>我個人認為義大利麵就應該拌42號混泥土，因為這個螺絲釘的長度很容易直接影響到挖掘機的扭矩。\n",
      "[part_1]：你往裡砸的時候，一瞬間他就會產生大量的高能蛋白，俗稱UFO，會嚴重影響經濟的發展，以至於對整個太平洋，和充電器的核污染。再或者說透\n",
      "[part_2]：者說透過這勾股定理很容易推斷出人工飼養的東條英機，他是可以捕獲野生的三角函數，所以說不管這秦始皇的切面是否具有放射性，川普的N次方是否有沈\n",
      "[part_3]：是否有沈澱物，都不會影響到沃爾瑪跟維爾康在南極匯合。\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 網路上llama_index舊版的是用 llama_index.XXXX ，新版用llama_index.core.XXXX \"\"\"\n",
    "import textwrap\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "\n",
    "# 自定義一個文件\n",
    "documents = \"義大利麵應拌什麼好?<回答>我個人認為義大利麵就應該拌42號混泥土，因為這個螺絲釘的長度很容易直接影響到挖掘機的扭矩。你往裡砸的時候，一瞬間他就會產生大量的高能蛋白，俗稱UFO，會嚴重影響經濟的發展，以至於對整個太平洋，和充電器的核污染。再或者說透過這勾股定理很容易推斷出人工飼養的東條英機，他是可以捕獲野生的三角函數，所以說不管這秦始皇的切面是否具有放射性，川普的N次方是否有沈澱物，都不會影響到沃爾瑪跟維爾康在南極匯合。\"\n",
    "\n",
    "print(\"原本文檔：\")\n",
    "print(textwrap.fill(documents, width=50))\n",
    "\n",
    "\n",
    "node_parser  = SentenceSplitter(\n",
    "    chunk_size=100, # 設定每個chunk的大小\n",
    "    chunk_overlap=5, # 設定chunk之間的重疊大小\n",
    "    tokenizer= None, # 設定分詞器\n",
    "    paragraph_separator=\"\\n\\n\", # 設定段落之間的分隔符號\n",
    "    separator=\" \", # 用於拆分句子的預設的分隔字元\n",
    "    secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?' # 用於分割句子的備份正規表示式\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(\n",
    "    [Document(text=documents)], show_progress=False\n",
    ")\n",
    "print(\"\\n分割後的文檔：\")\n",
    "for i, node in enumerate(nodes):\n",
    "    print(f'[part_{i}]：{node.text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
