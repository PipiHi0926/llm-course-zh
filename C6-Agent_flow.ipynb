{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:small; color:gray;\"> Author: 鄭永誠, Year: 2024 </p>\n",
    "\n",
    "# 使用LangGraph實踐LLM Agent流程 - 2\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 讓print出來資訊變彩色的可愛套件 '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 讓print出來資訊變彩色的可愛套件 \"\"\"\n",
    "# %pip install termcolor -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 首先，我先設定了這邊要用的LLM模型\n",
    "(當然，你也可以讓不同Agent使用不同模型唷! 也是種策略)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Setup LLM Model with GROQ API \"\"\"\n",
    "\n",
    "\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "import requests\n",
    "from typing import List\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "END = '__end__'\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "class GroqModel:\n",
    "    def __init__(self, temperature=0, model=None):\n",
    "        self.api_key = \"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\"\n",
    "        self.headers = {\n",
    "            'Content-Type': 'application/json', \n",
    "            'Authorization': f'Bearer {self.api_key}'\n",
    "            }\n",
    "        self.model_endpoint = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, messages):\n",
    "\n",
    "        system = messages[0][\"content\"]\n",
    "        user = messages[1][\"content\"]\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"system:{system}\\n\\n user:{user}\"\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            request_response = requests.post(\n",
    "                self.model_endpoint, \n",
    "                headers=self.headers, \n",
    "                data=json.dumps(payload)\n",
    "                )\n",
    "            \n",
    "            print(\"REQUEST RESPONSE\", request_response)\n",
    "            request_response_json = request_response.json()['choices'][0]['message']['content']\n",
    "            response = str(request_response_json)\n",
    "            \n",
    "            response_formatted = HumanMessage(content=response)\n",
    "\n",
    "            return response_formatted\n",
    "        except requests.RequestException as e:\n",
    "            response = {\"error\": f\"Error in invoking model! {str(e)}\"}\n",
    "            response_formatted = HumanMessage(content=response)\n",
    "            return response_formatted\n",
    "        \n",
    "class GroqJSONModel:\n",
    "    def __init__(self, temperature=0, model=None):\n",
    "        self.api_key = \"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\"\n",
    "        self.headers = {\n",
    "            'Content-Type': 'application/json', \n",
    "            'Authorization': f'Bearer {self.api_key}'\n",
    "            }\n",
    "        self.model_endpoint = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, messages):\n",
    "\n",
    "        system = messages[0][\"content\"]\n",
    "        user = messages[1][\"content\"]\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"system:{system}\\n\\n user:{user}\"\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"response_format\": {\"type\": \"json_object\"}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            request_response = requests.post(\n",
    "                self.model_endpoint, \n",
    "                headers=self.headers, \n",
    "                data=json.dumps(payload)\n",
    "            )\n",
    "            \n",
    "            print(\"REQUEST RESPONSE\", request_response.status_code)\n",
    "            # print(\"REQUEST RESPONSE HEADERS\", request_response.headers)\n",
    "            # print(\"REQUEST RESPONSE TEXT\", request_response.text)\n",
    "            \n",
    "            request_response_json = request_response.json()\n",
    "            # print(\"REQUEST RESPONSE JSON\", request_response_json)\n",
    "            \n",
    "            if 'choices' not in request_response_json or len(request_response_json['choices']) == 0:\n",
    "                raise ValueError(\"No choices in response\")\n",
    "\n",
    "            response_content = request_response_json['choices'][0]['message']['content']\n",
    "            # print(\"RESPONSE CONTENT\", response_content)\n",
    "            \n",
    "            response = json.loads(response_content)\n",
    "            response = json.dumps(response)\n",
    "\n",
    "            response_formatted = HumanMessage(content=response)\n",
    "\n",
    "            return response_formatted\n",
    "        except (requests.RequestException, ValueError, KeyError) as e:\n",
    "            error_message = f\"Error in invoking model! {str(e)}\"\n",
    "            print(\"ERROR\", error_message)\n",
    "            response = {\"error\": error_message}\n",
    "            response_formatted = HumanMessage(content=json.dumps(response))\n",
    "            return response_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定義一個AgentGraphState，存儲所有 Agent 的狀態信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "建立 Agent Graph State，確認並記錄各 Agent 流程 \n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 定義 Agent Graph 的狀態對象\n",
    "# 這裡使用 TypedDict 來定義字典結構，每個 Agent 的回應都以一個列表表示\n",
    "class AgentGraphState(TypedDict):\n",
    "    research_question: str  # 研究問題，表示當前要解決的問題或任務\n",
    "    planner_response: Annotated[list, add_messages]  # 計劃者的回應\n",
    "    selector_response: Annotated[list, add_messages]  # 選擇者的回應\n",
    "    reporter_response: Annotated[list, add_messages]  # 報告者的回應\n",
    "    reviewer_response: Annotated[list, add_messages]  # 審核者的回應\n",
    "    router_response: Annotated[list, add_messages]  # 路由者的回應\n",
    "    serper_response: Annotated[list, add_messages]  # 搜尋者的回應\n",
    "    scraper_response: Annotated[list, add_messages]  # 爬取者的回應\n",
    "    final_reports: Annotated[list, add_messages]  # 最終報告\n",
    "    end_chain: Annotated[list, add_messages]  # 鏈結結束\n",
    "\n",
    "# 定義獲取 Agent Graph 狀態的方法\n",
    "# 這個方法根據給定的 state_key 返回對應的 Agent 回應數據\n",
    "def get_agent_graph_state(state: AgentGraphState, state_key: str):\n",
    "    if state_key == \"planner_all\":\n",
    "        return state[\"planner_response\"]  # 返回計劃者的所有回應\n",
    "    elif state_key == \"planner_latest\":\n",
    "        if state[\"planner_response\"]:\n",
    "            return state[\"planner_response\"][-1]  # 返回計劃者的最新回應\n",
    "        else:\n",
    "            return state[\"planner_response\"]  # 如果沒有回應，返回空列表\n",
    "\n",
    "    elif state_key == \"selector_all\":\n",
    "        return state[\"selector_response\"]  # 返回選擇者的所有回應\n",
    "    elif state_key == \"selector_latest\":\n",
    "        if state[\"selector_response\"]:\n",
    "            return state[\"selector_response\"][-1]  # 返回選擇者的最新回應\n",
    "        else:\n",
    "            return state[\"selector_response\"]  # 如果沒有回應，返回空列表\n",
    "\n",
    "    elif state_key == \"reporter_all\":\n",
    "        return state[\"reporter_response\"]  # 返回報告者的所有回應\n",
    "    elif state_key == \"reporter_latest\":\n",
    "        if state[\"reporter_response\"]:\n",
    "            return state[\"reporter_response\"][-1]  # 返回報告者的最新回應\n",
    "        else:\n",
    "            return state[\"reporter_response\"]  # 如果沒有回應，返回空列表\n",
    "\n",
    "    elif state_key == \"reviewer_all\":\n",
    "        return state[\"reviewer_response\"]  # 返回審核者的所有回應\n",
    "    elif state_key == \"reviewer_latest\":\n",
    "        if state[\"reviewer_response\"]:\n",
    "            return state[\"reviewer_response\"][-1]  # 返回審核者的最新回應\n",
    "        else:\n",
    "            return state[\"reviewer_response\"]  # 如果沒有回應，返回空列表\n",
    "\n",
    "    elif state_key == \"serper_all\":\n",
    "        return state[\"serper_response\"]  # 返回搜尋者的所有回應\n",
    "    elif state_key == \"serper_latest\":\n",
    "        if state[\"serper_response\"]:\n",
    "            return state[\"serper_response\"][-1]  # 返回搜尋者的最新回應\n",
    "        else:\n",
    "            return state[\"serper_response\"]  # 如果沒有回應，返回空列表\n",
    "\n",
    "    elif state_key == \"scraper_all\":\n",
    "        return state[\"scraper_response\"]  # 返回爬取者的所有回應\n",
    "    elif state_key == \"scraper_latest\":\n",
    "        if state[\"scraper_response\"]:\n",
    "            return state[\"scraper_response\"][-1]  # 返回爬取者的最新回應\n",
    "        else:\n",
    "            return state[\"scraper_response\"]  # 如果沒有回應，返回空列表\n",
    "\n",
    "    else:\n",
    "        return None  # 如果 state_key 不匹配任何情況，返回 None\n",
    "    \n",
    "# 初始化 Agent Graph 的狀態\n",
    "# 所有的回應列表都初始化為空列表，並且研究問題初始化為空字符串\n",
    "state = {\n",
    "    \"research_question\": \"\",\n",
    "    \"planner_response\": [],\n",
    "    \"selector_response\": [],\n",
    "    \"reporter_response\": [],\n",
    "    \"reviewer_response\": [],\n",
    "    \"router_response\": [],\n",
    "    \"serper_response\": [],\n",
    "    \"scraper_response\": [],\n",
    "    \"final_reports\": [],\n",
    "    \"end_chain\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 一些工具和輔助function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 設定工具和其他一些輔助函數 \"\"\"\n",
    "import os\n",
    "\n",
    "import json \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.messages import HumanMessage\n",
    "from datetime import datetime, timezone\n",
    "from langchain_anthropic.chat_models import ChatAnthropic\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from typing import List\n",
    "from typing import Literal\n",
    "\n",
    "END = '__end__'\n",
    "\n",
    "\n",
    "# 亂碼的檢測函數\n",
    "def is_garbled(text):\n",
    "    # 簡單的檢測亂碼的啟發式方法：當非 ASCII 字符比例高判定為亂碼\n",
    "    non_ascii_count = sum(1 for char in text if ord(char) > 127)\n",
    "    return non_ascii_count > len(text) * 0.3\n",
    "\n",
    "# 熟悉的美麗湯，用來抓取網頁內容\n",
    "\n",
    "def scrape_website(state: AgentGraphState, research=None):\n",
    "    research_data = research().content\n",
    "    research_data = json.loads(research_data)\n",
    "    # research_data = ast.literal_eval(research_data)\n",
    "\n",
    "    try:\n",
    "        url = research_data[\"selected_page_url\"]\n",
    "    except KeyError as e:\n",
    "        url = research_data[\"error\"]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract text content\n",
    "        texts = soup.stripped_strings\n",
    "        content = ' '.join(texts)\n",
    "        \n",
    "        # Check for garbled text\n",
    "        if is_garbled(content):\n",
    "            content = \"error in scraping website, garbled text returned\"\n",
    "        else:\n",
    "            # Limit the content to 4000 characters\n",
    "            content = content[:4000]\n",
    "\n",
    "        state[\"scraper_response\"].append(HumanMessage(role=\"system\", content=str({\"source\": url, \"content\": content})))\n",
    "        \n",
    "        return {\"scraper_response\": state[\"scraper_response\"]}\n",
    "    \n",
    "    except requests.HTTPError as e:\n",
    "        if e.response.status_code == 403:\n",
    "            content = f\"error in scraping website, 403 Forbidden for url: {url}\"\n",
    "        else:\n",
    "            content = f\"error in scraping website, {str(e)}\"\n",
    "        \n",
    "        state[\"scraper_response\"].append(HumanMessage(role=\"system\", content=str({\"source\": url, \"content\": content})))\n",
    "        return {\"scraper_response\": state[\"scraper_response\"]}\n",
    "    except requests.RequestException as e:\n",
    "        content = f\"error in scraping website, {str(e)}\"\n",
    "        state[\"scraper_response\"].append(HumanMessage(role=\"system\", content=str({\"source\": url, \"content\": content})))\n",
    "        return {\"scraper_response\": state[\"scraper_response\"]}\n",
    "\n",
    "\n",
    "\n",
    "# 用來獲取當前 UTC 日期和時間\n",
    "def get_current_utc_datetime():\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    current_time_utc = now_utc.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "    return current_time_utc\n",
    "\n",
    "# 用來檢查狀態字典中的屬性是否有內容\n",
    "def check_for_content(var):\n",
    "    if var:\n",
    "        try:\n",
    "            var = var.content\n",
    "            return var.content\n",
    "        except:\n",
    "            return var\n",
    "    else:\n",
    "        var\n",
    "\n",
    "# 用於格式化搜索結果\n",
    "def format_results(organic_results):\n",
    "\n",
    "        result_strings = []\n",
    "        for result in organic_results:\n",
    "            title = result.get('title', 'No Title')\n",
    "            link = result.get('link', '#')\n",
    "            snippet = result.get('snippet', 'No snippet available.')\n",
    "            result_strings.append(f\"Title: {title}\\nLink: {link}\\nSnippet: {snippet}\\n---\")\n",
    "        \n",
    "        return '\\n'.join(result_strings)\n",
    "\n",
    "# 定義一個函數，用於從 Google Serper API 獲取搜索結果\n",
    "# 注意，一樣要改成填入自己的 API 金鑰\n",
    "def get_google_serper(state:AgentGraphState, plan):\n",
    "\n",
    "    plan_data = plan().content\n",
    "    plan_data = json.loads(plan_data)\n",
    "    search = plan_data.get(\"search_term\")\n",
    "\n",
    "    # 從.env檔取得API key\n",
    "    api_key = os.getenv('X-API-KEY')\n",
    "\n",
    "    search_url = \"https://google.serper.dev/search\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'X-API-KEY': api_key  \n",
    "    }\n",
    "    payload = json.dumps({\"q\": search})\n",
    "    \n",
    "    # Attempt to make the HTTP POST request\n",
    "    try:\n",
    "        response = requests.post(search_url, headers=headers, data=payload)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4XX, 5XX)\n",
    "        results = response.json()\n",
    "        \n",
    "        # Check if 'organic' results are in the response\n",
    "        if 'organic' in results:\n",
    "            formatted_results = format_results(results['organic'])\n",
    "            state = {**state, \"serper_response\": formatted_results}\n",
    "            return state\n",
    "        else:\n",
    "            return {**state, \"serper_response\": \"No organic results found.\"}\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        return {**state, \"serper_response\": f\"HTTP error occurred: {http_err}\"}\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        return {**state, \"serper_response\": f\"Request error occurred: {req_err}\"}\n",
    "    except KeyError as key_err:\n",
    "        return {**state, \"serper_response\": f\"Key error occurred: {key_err}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 設定各 Agent 的 system prompt \n",
    "1. **Planner（規劃者）:**\n",
    "- 功能: 負責為研究問題制定一個全面的計劃，指導團隊如何有效地進行搜索。規劃者需根據收到的反饋調整計劃，並強調最相關的搜索詞，幫助其他團隊成員進行信息搜索。\n",
    "\n",
    "- 輸出格式: JSON 格式，包含搜索詞、整體策略和附加信息。\n",
    "\n",
    "\n",
    "2. **Selector（選擇者）**\n",
    "- 功能: 負責從搜索引擎結果頁面中選擇最相關的搜索結果，並提供選擇的詳細原因。選擇者根據收到的反饋來調整選擇的結果。\n",
    "- 輸出格式: JSON 格式，包含選擇的頁面URL、簡短描述和選擇原因。\n",
    "\n",
    "3. **Reporter（報告者）**\n",
    "- 功能: 負責根據所選擇的網頁內容，撰寫一個全面的回應，回答研究問題。報告者必須引用並參考信息來源，並根據反饋調整回應。\n",
    "- 輸出格式: 結構化的文本回答，引用來源需標明URL。\n",
    "\n",
    "4. **Reviewer（審核者）**\n",
    "- 功能: 審核報告者的回應，並提供反饋。反饋應包括是否通過審核以及改進建議。審核者還需要考慮之前的代理工作結果。\n",
    "- 輸出格式: JSON 格式，包含反饋意見、是否通過審核、是否全面、是否提供引用、是否與研究問題相關。\n",
    "\n",
    "5. **Router（流程決策者）**\n",
    "- 功能: 負責根據審核者提供的反饋決定下一步行動，選擇下一個應該接手任務的代理。可能的選擇包括規劃者、選擇者、報告者或進入最終報告階段。\n",
    "- 輸出格式: JSON 格式，指定下一個代理。\n",
    "\n",
    "\n",
    "這些角色之間協作，形成一個完整的工作流程，用於解決複雜的研究問題。每個角色在處理過程中都根據接收到的反饋進行調整和優化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 設定各Agent的prompt\"\"\"\n",
    "planner_prompt_template = \"\"\"\n",
    "你是一名規劃者。你的責任是制定一個全面的計劃來幫助你的團隊回答一個研究問題。\n",
    "問題可能從簡單到複雜的多步驟查詢。你的計劃應該為你的團隊提供適當的指導，以有效地使用互聯網搜索引擎。\n",
    "\n",
    "重點強調最相關的搜索詞開始，因為另一個團隊成員將使用你的建議搜索相關信息。\n",
    "\n",
    "都要使用utf-8格式回答\n",
    "\n",
    "如果你收到反饋，你必須相應地調整你的計劃。這裡是收到的反饋：\n",
    "反饋：{feedback}\n",
    "\n",
    "當前日期和時間：\n",
    "{datetime}\n",
    "\n",
    "你的回應必須採用以下 json 格式並用UTF-8編碼：\n",
    "\n",
    "    \"search_term\": \"最相關的搜索詞開始\"\n",
    "    \"overall_strategy\": \"指導搜索過程的整體策略\"\n",
    "    \"additional_information\": \"指導搜索的其他信息，包括其他搜索詞或過濾器\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "planner_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"search_term\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"最相關的搜索詞開始\"\n",
    "        },\n",
    "        \"overall_strategy\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"指導搜索過程的整體策略\"\n",
    "        },\n",
    "        \"additional_information\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"指導搜索的其他信息，包括其他搜索詞或過濾器\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"search_term\", \"overall_strategy\", \"additional_information\"]\n",
    "}\n",
    "\n",
    "\n",
    "selector_prompt_template = \"\"\"\n",
    "你是一名選擇者。你將看到一個包含潛在相關搜索結果的搜索引擎結果頁面。你的任務是檢視所有結果，選擇最相關的一個，並提供選擇的詳細原因。\n",
    "\n",
    "這是搜索引擎結果頁面：\n",
    "{serp}\n",
    "\n",
    "請以以下 json 格式返回你的發現，並用UTF-8編碼：\n",
    "\n",
    "    \"selected_page_url\": \"你選擇的頁面精確URL\",\n",
    "    \"description\": \"頁面的簡短描述\",\n",
    "    \"reason_for_selection\": \"你選擇此頁面的原因\"\n",
    "\n",
    "根據收到的反饋調整你的選擇：\n",
    "反饋：{feedback}\n",
    "\n",
    "這是你之前的選擇：\n",
    "{previous_selections}\n",
    "在做出新的選擇時請考慮這些信息。\n",
    "\n",
    "當前日期和時間：\n",
    "{datetime}\n",
    "\"\"\"\n",
    "\n",
    "selector_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"selected_page_url\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"你選擇的頁面精確URL\"\n",
    "        },\n",
    "        \"description\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"頁面的簡短描述\"\n",
    "        },\n",
    "        \"reason_for_selection\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"你選擇此頁面的原因\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"selected_page_url\", \"description\", \"reason_for_selection\"]\n",
    "}\n",
    "\n",
    "\n",
    "reporter_prompt_template = \"\"\"\n",
    "你是一名報告者。你將看到一個包含與研究問題相關信息的網頁。你的任務是根據頁面上的信息提供一個全面的答案。確保引用和參考你的來源。\n",
    "\n",
    "研究將以字典的形式呈現，來源為URL，內容為頁面上的文本：\n",
    "研究：{research}\n",
    "\n",
    "結構化你的回應如下：\n",
    "根據收集到的信息，這是對查詢的全面回應：\n",
    "\"天空看起來是藍色的，因為一種稱為瑞利散射的現象，這種現象使得較短波長的光（藍色）比較長波長的光（紅色）散射更多 [1]。這種散射使天空大部分時間看起來是藍色的 [1]。此外，在日出和日落時，天空可能看起來是紅色或橙色，因為光線必須穿過更多的大氣層，將較短的藍色波長散射出視線，讓較長的紅色波長占主導地位 [2]。\"\n",
    "\n",
    "來源：\n",
    "[1] https://example.com/science/why-is-the-sky-blue\n",
    "[2] https://example.com/science/sunrise-sunset-colors\n",
    "\n",
    "根據收到的反饋調整你的回應：\n",
    "反饋：{feedback}\n",
    "\n",
    "這是你之前的報告：\n",
    "{previous_reports}\n",
    "\n",
    "當前日期和時間：\n",
    "{datetime}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "reviewer_prompt_template = \"\"\"\n",
    "你是一名審核者。你的任務是審核報告者對研究問題的回應並提供反饋。\n",
    "\n",
    "這是報告者的回應：\n",
    "報告者的回應：{reporter}\n",
    "\n",
    "你的反饋應包括通過或未通過審核的原因和改進建議。\n",
    "\n",
    "在提供新反饋時應考慮你之前給出的反饋。\n",
    "反饋：{feedback}\n",
    "\n",
    "當前日期和時間：\n",
    "{datetime}\n",
    "\n",
    "你應該了解之前代理的所做工作。你可以在代理狀態中看到這些信息：\n",
    "代理狀態：{state}\n",
    "\n",
    "你的回應必須採用以下 json 格式，並用UTF-8編碼：\n",
    "\n",
    "    \"feedback\": \"如果回應未通過審核，請提供具體反饋以便通過審核。\",\n",
    "    \"pass_review\": \"True/False\",\n",
    "    \"comprehensive\": \"True/False\",\n",
    "    \"citations_provided\": \"True/False\",\n",
    "    \"relevant_to_research_question\": \"True/False\",\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "reviewer_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"feedback\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"你的反饋。說明為什麼你通過或未通過審核\"\n",
    "        },\n",
    "        \"pass_review\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        },\n",
    "        \"comprehensive\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        },\n",
    "        \"citations_provided\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        },\n",
    "        \"relevant_to_research_question\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"feedback\", \"pass_review\", \"comprehensive\", \"citations_provided\", \"relevant_to_research_question\"]\n",
    "}\n",
    "\n",
    "router_prompt_template = \"\"\"\n",
    "你是一名流程決策者。你的任務是根據審核者提供的反饋將對話決策到下一個代理。你必須選擇以下代理之一：規劃者、選擇者、報告者或最終報告。\n",
    "\n",
    "這是審核者提供的反饋：\n",
    "反饋：{feedback}\n",
    "\n",
    "### 選擇下一個代理的標準：\n",
    "- **規劃者**：如果需要新信息。\n",
    "- **選擇者**：如果需要選擇不同的來源。\n",
    "- **報告者**：如果報告的格式或風格需要改進，或如果回應缺乏清晰性或全面性。\n",
    "- **最終報告**：如果反饋標記為通過審核（pass_review）為True，你必須選擇最終報告。\n",
    "\n",
    "你必須以以下 json 格式提供你的回應，並用UTF-8編碼：\n",
    "    \n",
    "        \"next_agent\": \"規劃者/選擇者/報告者/最終報告 之一\"\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 建立各個Agent (class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 建立各個Agent \"\"\"\n",
    "from termcolor import colored\n",
    "import json\n",
    "def handle_encoding(text):\n",
    "    # 將 JSON 字符串轉換成 Python 字典\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        return data\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state: AgentGraphState, model=None, server=None, temperature=0, model_endpoint=None, stop=None, guided_json=None):\n",
    "        self.state = state\n",
    "        self.model = model\n",
    "        self.server = server\n",
    "        self.temperature = temperature\n",
    "        self.model_endpoint = model_endpoint\n",
    "        self.stop = stop\n",
    "        self.guided_json = guided_json\n",
    "\n",
    "    def get_llm(self, json_model=True):\n",
    "\n",
    "        if self.server == 'groq':\n",
    "            return GroqJSONModel(\n",
    "                model=self.model,\n",
    "                temperature=self.temperature\n",
    "            ) if json_model else GroqModel(\n",
    "                model=self.model,\n",
    "                temperature=self.temperature\n",
    "            )\n",
    "\n",
    "\n",
    "    def update_state(self, key, value):\n",
    "        self.state = {**self.state, key: value}\n",
    "\n",
    "class PlannerAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=planner_prompt_template, feedback=None):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "\n",
    "        planner_prompt = prompt.format(\n",
    "            feedback=feedback_value,\n",
    "            datetime=get_current_utc_datetime()\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": planner_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        self.update_state(\"planner_response\", response)\n",
    "        print(colored(f\"規劃者 Planner 👩🏿‍💻:\\n {show_response}\", 'cyan'))\n",
    "        return self.state\n",
    "\n",
    "class SelectorAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=selector_prompt_template, feedback=None, previous_selections=None, serp=None):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        previous_selections_value = previous_selections() if callable(previous_selections) else previous_selections\n",
    "\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "        previous_selections_value = check_for_content(previous_selections_value)\n",
    "\n",
    "        selector_prompt = prompt.format(\n",
    "            feedback=feedback_value,\n",
    "            previous_selections=previous_selections_value,\n",
    "            serp=serp().content,\n",
    "            datetime=get_current_utc_datetime()\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": selector_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"選擇者 Selector 🧑🏼‍💻:\\n {show_response}\", 'green'))\n",
    "        self.update_state(\"selector_response\", response)\n",
    "        return self.state\n",
    "\n",
    "class ReporterAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=reporter_prompt_template, feedback=None, previous_reports=None, research=None):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        previous_reports_value = previous_reports() if callable(previous_reports) else previous_reports\n",
    "        research_value = research() if callable(research) else research\n",
    "\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "        previous_reports_value = check_for_content(previous_reports_value)\n",
    "        research_value = check_for_content(research_value)\n",
    "        \n",
    "        reporter_prompt = prompt.format(\n",
    "            feedback=feedback_value,\n",
    "            previous_reports=previous_reports_value,\n",
    "            datetime=get_current_utc_datetime(),\n",
    "            research=research_value\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": reporter_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm(json_model=False)\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"報告者 Reporter 👨‍💻:\\n {show_response}\", 'yellow'))\n",
    "        self.update_state(\"reporter_response\", response)\n",
    "        return self.state\n",
    "\n",
    "class ReviewerAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=reviewer_prompt_template, reporter=None, feedback=None):\n",
    "        reporter_value = reporter() if callable(reporter) else reporter\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "\n",
    "        reporter_value = check_for_content(reporter_value)\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "        \n",
    "        reviewer_prompt = prompt.format(\n",
    "            reporter=reporter_value,\n",
    "            state=self.state,\n",
    "            feedback=feedback_value,\n",
    "            datetime=get_current_utc_datetime(),\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": reviewer_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"查核者 Reviewer 👩🏽‍⚖️:\\n {show_response}\", 'magenta'))\n",
    "        self.update_state(\"reviewer_response\", response)\n",
    "        return self.state\n",
    "    \n",
    "class RouterAgent(Agent):\n",
    "    def invoke(self, feedback=None, research_question=None, prompt=router_prompt_template):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "\n",
    "        router_prompt = prompt.format(feedback=feedback_value)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": router_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"指派者 Router 🧭:\\n {show_response}\", 'blue'))\n",
    "        self.update_state(\"router_response\", response)\n",
    "        return self.state\n",
    "\n",
    "class FinalReportAgent(Agent):\n",
    "    def invoke(self, final_response=None):\n",
    "        final_response_value = final_response() if callable(final_response) else final_response\n",
    "        response = final_response_value.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"Final Report 📝:\\n {show_response}\", 'blue'))\n",
    "        self.update_state(\"final_reports\", response)\n",
    "        return self.state\n",
    "\n",
    "class EndNodeAgent(Agent):\n",
    "    def invoke(self):\n",
    "        self.update_state(\"end_chain\", \"end_chain\")\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 建立 Agent Graph 間關聯的流程圖\n",
    "- 用add_node方法添加節點  \n",
    "\n",
    "- 用add_edge增加節點間流程\n",
    "\n",
    "- 用add_conditional_edges增加節點間條件流程\n",
    "\n",
    "- 用set_entry_point設定開始節點\n",
    "\n",
    "- 用set_finish_point設定結束節點\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Agent Graph \"\"\"\n",
    "import json\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "router_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"next_agent\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"one of the following: planner/selector/reporter/final_report\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"next_agent\"]\n",
    "}\n",
    "\n",
    "\n",
    "def create_graph(server=None, model=None, stop=None, model_endpoint=None, temperature=0):\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    graph.add_node(\n",
    "        \"planner\", \n",
    "        lambda state: PlannerAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=planner_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            # previous_plans=lambda: get_agent_graph_state(state=state, state_key=\"planner_all\"),\n",
    "            prompt=planner_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"selector\",\n",
    "        lambda state: SelectorAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=selector_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            previous_selections=lambda: get_agent_graph_state(state=state, state_key=\"selector_all\"),\n",
    "            serp=lambda: get_agent_graph_state(state=state, state_key=\"serper_latest\"),\n",
    "            prompt=selector_prompt_template,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"reporter\", \n",
    "        lambda state: ReporterAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            previous_reports=lambda: get_agent_graph_state(state=state, state_key=\"reporter_all\"),\n",
    "            research=lambda: get_agent_graph_state(state=state, state_key=\"scraper_latest\"),\n",
    "            prompt=reporter_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"reviewer\", \n",
    "        lambda state: ReviewerAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=reviewer_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_all\"),\n",
    "            reporter=lambda: get_agent_graph_state(state=state, state_key=\"reporter_latest\"),\n",
    "            prompt=reviewer_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"router\", \n",
    "        lambda state: RouterAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=router_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_all\"),\n",
    "            prompt=router_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    graph.add_node(\n",
    "        \"serper_tool\",\n",
    "        lambda state: get_google_serper(\n",
    "            state=state,\n",
    "            plan=lambda: get_agent_graph_state(state=state, state_key=\"planner_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"scraper_tool\",\n",
    "        lambda state: scrape_website(\n",
    "            state=state,\n",
    "            research=lambda: get_agent_graph_state(state=state, state_key=\"selector_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"final_report\", \n",
    "        lambda state: FinalReportAgent(\n",
    "            state=state\n",
    "        ).invoke(\n",
    "            final_response=lambda: get_agent_graph_state(state=state, state_key=\"reporter_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\"end\", lambda state: EndNodeAgent(state).invoke())\n",
    "\n",
    "    # Define the edges in the agent graph\n",
    "    def pass_review(state: AgentGraphState):\n",
    "        review_list = state[\"router_response\"]\n",
    "        if review_list:\n",
    "            review = review_list[-1]\n",
    "        else:\n",
    "            review = \"No review\"\n",
    "\n",
    "        if review != \"No review\":\n",
    "            if isinstance(review, HumanMessage):\n",
    "                review_content = review.content\n",
    "            else:\n",
    "                review_content = review\n",
    "            \n",
    "            review_data = json.loads(review_content)\n",
    "            next_agent = review_data[\"next_agent\"]\n",
    "        else:\n",
    "            next_agent = \"end\"\n",
    "\n",
    "        return next_agent\n",
    "\n",
    "    # Add edges to the graph\n",
    "    graph.set_entry_point(\"planner\")\n",
    "    graph.set_finish_point(\"end\")\n",
    "    graph.add_edge(\"planner\", \"serper_tool\")\n",
    "    graph.add_edge(\"serper_tool\", \"selector\")\n",
    "    graph.add_edge(\"selector\", \"scraper_tool\")\n",
    "    graph.add_edge(\"scraper_tool\", \"reporter\")\n",
    "    graph.add_edge(\"reporter\", \"reviewer\")\n",
    "    graph.add_edge(\"reviewer\", \"router\")\n",
    "\n",
    "    graph.add_conditional_edges(\n",
    "        \"router\",\n",
    "        lambda state: pass_review(state=state),\n",
    "    )\n",
    "\n",
    "    graph.add_edge(\"final_report\", \"end\")\n",
    "    compiled_graph = graph.compile()\n",
    "    # display(Image(compiled_graph.get_graph().draw_mermaid_png()))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 定義一個建立 Agent Graph 並啟動的函式 \"\"\"\n",
    "def compile_workflow(graph):\n",
    "    workflow = graph.compile()\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實際操作範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST RESPONSE 524\n",
      "ERROR Error in invoking model! Expecting value: line 1 column 1 (char 0)\n",
      "\u001b[36m規劃者 Planner 👩🏿‍💻:\n",
      " {'error': 'Error in invoking model! Expecting value: line 1 column 1 (char 0)'}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "REQUEST RESPONSE 524\n",
      "ERROR Error in invoking model! Expecting value: line 1 column 1 (char 0)\n",
      "\u001b[32m選擇者 Selector 🧑🏼‍💻:\n",
      " {'error': 'Error in invoking model! Expecting value: line 1 column 1 (char 0)'}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 定義使用模型相關參數\n",
    "verbose = False\n",
    "iterations = 30\n",
    "server = 'groq'\n",
    "model = 'llama-3.1-70b-versatile'\n",
    "model_endpoint = None\n",
    "\n",
    "# call create_graph and compile_workflow\n",
    "graph = create_graph(server=server, model=model, model_endpoint=model_endpoint)\n",
    "workflow = compile_workflow(graph)\n",
    "\n",
    "\n",
    "while True:\n",
    "    query = input(\"Please enter your research question: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    dict_inputs = {\"research_question\": query}\n",
    "    # thread = {\"configurable\": {\"thread_id\": \"紀錄的thread_id\"}}\n",
    "    limit = {\"recursion_limit\": iterations}\n",
    "\n",
    "    \n",
    "    for event in workflow.stream(\n",
    "        dict_inputs, limit\n",
    "        ):\n",
    "        if verbose:\n",
    "            print(\"\\nState Dictionary:\", event)\n",
    "        else:\n",
    "            print(\"\\n\")\n",
    "\n",
    "# 執行後就可以輸入問句去問問題了\n",
    "# 問題範例: 下屆奧運辦在哪，為甚麼要辦在那裏?\n",
    "# 問題範例: 這個國家擅長甚麼運動項目?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
