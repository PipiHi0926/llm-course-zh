{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:small; color:gray;\"> Author: é„­æ°¸èª , Year: 2024 </p>\n",
    "\n",
    "# ä½¿ç”¨LangGraphå¯¦è¸LLM Agentæµç¨‹ - 2\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' è®“printå‡ºä¾†è³‡è¨Šè®Šå½©è‰²çš„å¯æ„›å¥—ä»¶ '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" è®“printå‡ºä¾†è³‡è¨Šè®Šå½©è‰²çš„å¯æ„›å¥—ä»¶ \"\"\"\n",
    "# %pip install termcolor -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. é¦–å…ˆï¼Œæˆ‘å…ˆè¨­å®šäº†é€™é‚Šè¦ç”¨çš„LLMæ¨¡å‹\n",
    "(ç•¶ç„¶ï¼Œä½ ä¹Ÿå¯ä»¥è®“ä¸åŒAgentä½¿ç”¨ä¸åŒæ¨¡å‹å”·! ä¹Ÿæ˜¯ç¨®ç­–ç•¥)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Setup LLM Model with GROQ API \"\"\"\n",
    "\n",
    "\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "import requests\n",
    "from typing import List\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "END = '__end__'\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "class GroqModel:\n",
    "    def __init__(self, temperature=0, model=None):\n",
    "        self.api_key = \"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\"\n",
    "        self.headers = {\n",
    "            'Content-Type': 'application/json', \n",
    "            'Authorization': f'Bearer {self.api_key}'\n",
    "            }\n",
    "        self.model_endpoint = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, messages):\n",
    "\n",
    "        system = messages[0][\"content\"]\n",
    "        user = messages[1][\"content\"]\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"system:{system}\\n\\n user:{user}\"\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            request_response = requests.post(\n",
    "                self.model_endpoint, \n",
    "                headers=self.headers, \n",
    "                data=json.dumps(payload)\n",
    "                )\n",
    "            \n",
    "            print(\"REQUEST RESPONSE\", request_response)\n",
    "            request_response_json = request_response.json()['choices'][0]['message']['content']\n",
    "            response = str(request_response_json)\n",
    "            \n",
    "            response_formatted = HumanMessage(content=response)\n",
    "\n",
    "            return response_formatted\n",
    "        except requests.RequestException as e:\n",
    "            response = {\"error\": f\"Error in invoking model! {str(e)}\"}\n",
    "            response_formatted = HumanMessage(content=response)\n",
    "            return response_formatted\n",
    "        \n",
    "class GroqJSONModel:\n",
    "    def __init__(self, temperature=0, model=None):\n",
    "        self.api_key = \"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\"\n",
    "        self.headers = {\n",
    "            'Content-Type': 'application/json', \n",
    "            'Authorization': f'Bearer {self.api_key}'\n",
    "            }\n",
    "        self.model_endpoint = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, messages):\n",
    "\n",
    "        system = messages[0][\"content\"]\n",
    "        user = messages[1][\"content\"]\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"system:{system}\\n\\n user:{user}\"\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": self.temperature,\n",
    "            \"response_format\": {\"type\": \"json_object\"}\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            request_response = requests.post(\n",
    "                self.model_endpoint, \n",
    "                headers=self.headers, \n",
    "                data=json.dumps(payload)\n",
    "            )\n",
    "            \n",
    "            print(\"REQUEST RESPONSE\", request_response.status_code)\n",
    "            # print(\"REQUEST RESPONSE HEADERS\", request_response.headers)\n",
    "            # print(\"REQUEST RESPONSE TEXT\", request_response.text)\n",
    "            \n",
    "            request_response_json = request_response.json()\n",
    "            # print(\"REQUEST RESPONSE JSON\", request_response_json)\n",
    "            \n",
    "            if 'choices' not in request_response_json or len(request_response_json['choices']) == 0:\n",
    "                raise ValueError(\"No choices in response\")\n",
    "\n",
    "            response_content = request_response_json['choices'][0]['message']['content']\n",
    "            # print(\"RESPONSE CONTENT\", response_content)\n",
    "            \n",
    "            response = json.loads(response_content)\n",
    "            response = json.dumps(response)\n",
    "\n",
    "            response_formatted = HumanMessage(content=response)\n",
    "\n",
    "            return response_formatted\n",
    "        except (requests.RequestException, ValueError, KeyError) as e:\n",
    "            error_message = f\"Error in invoking model! {str(e)}\"\n",
    "            print(\"ERROR\", error_message)\n",
    "            response = {\"error\": error_message}\n",
    "            response_formatted = HumanMessage(content=json.dumps(response))\n",
    "            return response_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. å®šç¾©ä¸€å€‹AgentGraphStateï¼Œå­˜å„²æ‰€æœ‰ Agent çš„ç‹€æ…‹ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "å»ºç«‹ Agent Graph Stateï¼Œç¢ºèªä¸¦è¨˜éŒ„å„ Agent æµç¨‹ \n",
    "\"\"\"\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# å®šç¾© Agent Graph çš„ç‹€æ…‹å°è±¡\n",
    "# é€™è£¡ä½¿ç”¨ TypedDict ä¾†å®šç¾©å­—å…¸çµæ§‹ï¼Œæ¯å€‹ Agent çš„å›æ‡‰éƒ½ä»¥ä¸€å€‹åˆ—è¡¨è¡¨ç¤º\n",
    "class AgentGraphState(TypedDict):\n",
    "    research_question: str  # ç ”ç©¶å•é¡Œï¼Œè¡¨ç¤ºç•¶å‰è¦è§£æ±ºçš„å•é¡Œæˆ–ä»»å‹™\n",
    "    planner_response: Annotated[list, add_messages]  # è¨ˆåŠƒè€…çš„å›æ‡‰\n",
    "    selector_response: Annotated[list, add_messages]  # é¸æ“‡è€…çš„å›æ‡‰\n",
    "    reporter_response: Annotated[list, add_messages]  # å ±å‘Šè€…çš„å›æ‡‰\n",
    "    reviewer_response: Annotated[list, add_messages]  # å¯©æ ¸è€…çš„å›æ‡‰\n",
    "    router_response: Annotated[list, add_messages]  # è·¯ç”±è€…çš„å›æ‡‰\n",
    "    serper_response: Annotated[list, add_messages]  # æœå°‹è€…çš„å›æ‡‰\n",
    "    scraper_response: Annotated[list, add_messages]  # çˆ¬å–è€…çš„å›æ‡‰\n",
    "    final_reports: Annotated[list, add_messages]  # æœ€çµ‚å ±å‘Š\n",
    "    end_chain: Annotated[list, add_messages]  # éˆçµçµæŸ\n",
    "\n",
    "# å®šç¾©ç²å– Agent Graph ç‹€æ…‹çš„æ–¹æ³•\n",
    "# é€™å€‹æ–¹æ³•æ ¹æ“šçµ¦å®šçš„ state_key è¿”å›å°æ‡‰çš„ Agent å›æ‡‰æ•¸æ“š\n",
    "def get_agent_graph_state(state: AgentGraphState, state_key: str):\n",
    "    if state_key == \"planner_all\":\n",
    "        return state[\"planner_response\"]  # è¿”å›è¨ˆåŠƒè€…çš„æ‰€æœ‰å›æ‡‰\n",
    "    elif state_key == \"planner_latest\":\n",
    "        if state[\"planner_response\"]:\n",
    "            return state[\"planner_response\"][-1]  # è¿”å›è¨ˆåŠƒè€…çš„æœ€æ–°å›æ‡‰\n",
    "        else:\n",
    "            return state[\"planner_response\"]  # å¦‚æœæ²’æœ‰å›æ‡‰ï¼Œè¿”å›ç©ºåˆ—è¡¨\n",
    "\n",
    "    elif state_key == \"selector_all\":\n",
    "        return state[\"selector_response\"]  # è¿”å›é¸æ“‡è€…çš„æ‰€æœ‰å›æ‡‰\n",
    "    elif state_key == \"selector_latest\":\n",
    "        if state[\"selector_response\"]:\n",
    "            return state[\"selector_response\"][-1]  # è¿”å›é¸æ“‡è€…çš„æœ€æ–°å›æ‡‰\n",
    "        else:\n",
    "            return state[\"selector_response\"]  # å¦‚æœæ²’æœ‰å›æ‡‰ï¼Œè¿”å›ç©ºåˆ—è¡¨\n",
    "\n",
    "    elif state_key == \"reporter_all\":\n",
    "        return state[\"reporter_response\"]  # è¿”å›å ±å‘Šè€…çš„æ‰€æœ‰å›æ‡‰\n",
    "    elif state_key == \"reporter_latest\":\n",
    "        if state[\"reporter_response\"]:\n",
    "            return state[\"reporter_response\"][-1]  # è¿”å›å ±å‘Šè€…çš„æœ€æ–°å›æ‡‰\n",
    "        else:\n",
    "            return state[\"reporter_response\"]  # å¦‚æœæ²’æœ‰å›æ‡‰ï¼Œè¿”å›ç©ºåˆ—è¡¨\n",
    "\n",
    "    elif state_key == \"reviewer_all\":\n",
    "        return state[\"reviewer_response\"]  # è¿”å›å¯©æ ¸è€…çš„æ‰€æœ‰å›æ‡‰\n",
    "    elif state_key == \"reviewer_latest\":\n",
    "        if state[\"reviewer_response\"]:\n",
    "            return state[\"reviewer_response\"][-1]  # è¿”å›å¯©æ ¸è€…çš„æœ€æ–°å›æ‡‰\n",
    "        else:\n",
    "            return state[\"reviewer_response\"]  # å¦‚æœæ²’æœ‰å›æ‡‰ï¼Œè¿”å›ç©ºåˆ—è¡¨\n",
    "\n",
    "    elif state_key == \"serper_all\":\n",
    "        return state[\"serper_response\"]  # è¿”å›æœå°‹è€…çš„æ‰€æœ‰å›æ‡‰\n",
    "    elif state_key == \"serper_latest\":\n",
    "        if state[\"serper_response\"]:\n",
    "            return state[\"serper_response\"][-1]  # è¿”å›æœå°‹è€…çš„æœ€æ–°å›æ‡‰\n",
    "        else:\n",
    "            return state[\"serper_response\"]  # å¦‚æœæ²’æœ‰å›æ‡‰ï¼Œè¿”å›ç©ºåˆ—è¡¨\n",
    "\n",
    "    elif state_key == \"scraper_all\":\n",
    "        return state[\"scraper_response\"]  # è¿”å›çˆ¬å–è€…çš„æ‰€æœ‰å›æ‡‰\n",
    "    elif state_key == \"scraper_latest\":\n",
    "        if state[\"scraper_response\"]:\n",
    "            return state[\"scraper_response\"][-1]  # è¿”å›çˆ¬å–è€…çš„æœ€æ–°å›æ‡‰\n",
    "        else:\n",
    "            return state[\"scraper_response\"]  # å¦‚æœæ²’æœ‰å›æ‡‰ï¼Œè¿”å›ç©ºåˆ—è¡¨\n",
    "\n",
    "    else:\n",
    "        return None  # å¦‚æœ state_key ä¸åŒ¹é…ä»»ä½•æƒ…æ³ï¼Œè¿”å› None\n",
    "    \n",
    "# åˆå§‹åŒ– Agent Graph çš„ç‹€æ…‹\n",
    "# æ‰€æœ‰çš„å›æ‡‰åˆ—è¡¨éƒ½åˆå§‹åŒ–ç‚ºç©ºåˆ—è¡¨ï¼Œä¸¦ä¸”ç ”ç©¶å•é¡Œåˆå§‹åŒ–ç‚ºç©ºå­—ç¬¦ä¸²\n",
    "state = {\n",
    "    \"research_question\": \"\",\n",
    "    \"planner_response\": [],\n",
    "    \"selector_response\": [],\n",
    "    \"reporter_response\": [],\n",
    "    \"reviewer_response\": [],\n",
    "    \"router_response\": [],\n",
    "    \"serper_response\": [],\n",
    "    \"scraper_response\": [],\n",
    "    \"final_reports\": [],\n",
    "    \"end_chain\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ä¸€äº›å·¥å…·å’Œè¼”åŠ©function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" è¨­å®šå·¥å…·å’Œå…¶ä»–ä¸€äº›è¼”åŠ©å‡½æ•¸ \"\"\"\n",
    "import os\n",
    "\n",
    "import json \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.messages import HumanMessage\n",
    "from datetime import datetime, timezone\n",
    "from langchain_anthropic.chat_models import ChatAnthropic\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from typing import List\n",
    "from typing import Literal\n",
    "\n",
    "END = '__end__'\n",
    "\n",
    "\n",
    "# äº‚ç¢¼çš„æª¢æ¸¬å‡½æ•¸\n",
    "def is_garbled(text):\n",
    "    # ç°¡å–®çš„æª¢æ¸¬äº‚ç¢¼çš„å•Ÿç™¼å¼æ–¹æ³•ï¼šç•¶é ASCII å­—ç¬¦æ¯”ä¾‹é«˜åˆ¤å®šç‚ºäº‚ç¢¼\n",
    "    non_ascii_count = sum(1 for char in text if ord(char) > 127)\n",
    "    return non_ascii_count > len(text) * 0.3\n",
    "\n",
    "# ç†Ÿæ‚‰çš„ç¾éº—æ¹¯ï¼Œç”¨ä¾†æŠ“å–ç¶²é å…§å®¹\n",
    "\n",
    "def scrape_website(state: AgentGraphState, research=None):\n",
    "    research_data = research().content\n",
    "    research_data = json.loads(research_data)\n",
    "    # research_data = ast.literal_eval(research_data)\n",
    "\n",
    "    try:\n",
    "        url = research_data[\"selected_page_url\"]\n",
    "    except KeyError as e:\n",
    "        url = research_data[\"error\"]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract text content\n",
    "        texts = soup.stripped_strings\n",
    "        content = ' '.join(texts)\n",
    "        \n",
    "        # Check for garbled text\n",
    "        if is_garbled(content):\n",
    "            content = \"error in scraping website, garbled text returned\"\n",
    "        else:\n",
    "            # Limit the content to 4000 characters\n",
    "            content = content[:4000]\n",
    "\n",
    "        state[\"scraper_response\"].append(HumanMessage(role=\"system\", content=str({\"source\": url, \"content\": content})))\n",
    "        \n",
    "        return {\"scraper_response\": state[\"scraper_response\"]}\n",
    "    \n",
    "    except requests.HTTPError as e:\n",
    "        if e.response.status_code == 403:\n",
    "            content = f\"error in scraping website, 403 Forbidden for url: {url}\"\n",
    "        else:\n",
    "            content = f\"error in scraping website, {str(e)}\"\n",
    "        \n",
    "        state[\"scraper_response\"].append(HumanMessage(role=\"system\", content=str({\"source\": url, \"content\": content})))\n",
    "        return {\"scraper_response\": state[\"scraper_response\"]}\n",
    "    except requests.RequestException as e:\n",
    "        content = f\"error in scraping website, {str(e)}\"\n",
    "        state[\"scraper_response\"].append(HumanMessage(role=\"system\", content=str({\"source\": url, \"content\": content})))\n",
    "        return {\"scraper_response\": state[\"scraper_response\"]}\n",
    "\n",
    "\n",
    "\n",
    "# ç”¨ä¾†ç²å–ç•¶å‰ UTC æ—¥æœŸå’Œæ™‚é–“\n",
    "def get_current_utc_datetime():\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    current_time_utc = now_utc.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "    return current_time_utc\n",
    "\n",
    "# ç”¨ä¾†æª¢æŸ¥ç‹€æ…‹å­—å…¸ä¸­çš„å±¬æ€§æ˜¯å¦æœ‰å…§å®¹\n",
    "def check_for_content(var):\n",
    "    if var:\n",
    "        try:\n",
    "            var = var.content\n",
    "            return var.content\n",
    "        except:\n",
    "            return var\n",
    "    else:\n",
    "        var\n",
    "\n",
    "# ç”¨æ–¼æ ¼å¼åŒ–æœç´¢çµæœ\n",
    "def format_results(organic_results):\n",
    "\n",
    "        result_strings = []\n",
    "        for result in organic_results:\n",
    "            title = result.get('title', 'No Title')\n",
    "            link = result.get('link', '#')\n",
    "            snippet = result.get('snippet', 'No snippet available.')\n",
    "            result_strings.append(f\"Title: {title}\\nLink: {link}\\nSnippet: {snippet}\\n---\")\n",
    "        \n",
    "        return '\\n'.join(result_strings)\n",
    "\n",
    "# å®šç¾©ä¸€å€‹å‡½æ•¸ï¼Œç”¨æ–¼å¾ Google Serper API ç²å–æœç´¢çµæœ\n",
    "# æ³¨æ„ï¼Œä¸€æ¨£è¦æ”¹æˆå¡«å…¥è‡ªå·±çš„ API é‡‘é‘°\n",
    "def get_google_serper(state:AgentGraphState, plan):\n",
    "\n",
    "    plan_data = plan().content\n",
    "    plan_data = json.loads(plan_data)\n",
    "    search = plan_data.get(\"search_term\")\n",
    "\n",
    "    # å¾.envæª”å–å¾—API key\n",
    "    api_key = os.getenv('X-API-KEY')\n",
    "\n",
    "    search_url = \"https://google.serper.dev/search\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'X-API-KEY': api_key  \n",
    "    }\n",
    "    payload = json.dumps({\"q\": search})\n",
    "    \n",
    "    # Attempt to make the HTTP POST request\n",
    "    try:\n",
    "        response = requests.post(search_url, headers=headers, data=payload)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4XX, 5XX)\n",
    "        results = response.json()\n",
    "        \n",
    "        # Check if 'organic' results are in the response\n",
    "        if 'organic' in results:\n",
    "            formatted_results = format_results(results['organic'])\n",
    "            state = {**state, \"serper_response\": formatted_results}\n",
    "            return state\n",
    "        else:\n",
    "            return {**state, \"serper_response\": \"No organic results found.\"}\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        return {**state, \"serper_response\": f\"HTTP error occurred: {http_err}\"}\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        return {**state, \"serper_response\": f\"Request error occurred: {req_err}\"}\n",
    "    except KeyError as key_err:\n",
    "        return {**state, \"serper_response\": f\"Key error occurred: {key_err}\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è¨­å®šå„ Agent çš„ system prompt \n",
    "1. **Plannerï¼ˆè¦åŠƒè€…ï¼‰:**\n",
    "- åŠŸèƒ½: è² è²¬ç‚ºç ”ç©¶å•é¡Œåˆ¶å®šä¸€å€‹å…¨é¢çš„è¨ˆåŠƒï¼ŒæŒ‡å°åœ˜éšŠå¦‚ä½•æœ‰æ•ˆåœ°é€²è¡Œæœç´¢ã€‚è¦åŠƒè€…éœ€æ ¹æ“šæ”¶åˆ°çš„åé¥‹èª¿æ•´è¨ˆåŠƒï¼Œä¸¦å¼·èª¿æœ€ç›¸é—œçš„æœç´¢è©ï¼Œå¹«åŠ©å…¶ä»–åœ˜éšŠæˆå“¡é€²è¡Œä¿¡æ¯æœç´¢ã€‚\n",
    "\n",
    "- è¼¸å‡ºæ ¼å¼: JSON æ ¼å¼ï¼ŒåŒ…å«æœç´¢è©ã€æ•´é«”ç­–ç•¥å’Œé™„åŠ ä¿¡æ¯ã€‚\n",
    "\n",
    "\n",
    "2. **Selectorï¼ˆé¸æ“‡è€…ï¼‰**\n",
    "- åŠŸèƒ½: è² è²¬å¾æœç´¢å¼•æ“çµæœé é¢ä¸­é¸æ“‡æœ€ç›¸é—œçš„æœç´¢çµæœï¼Œä¸¦æä¾›é¸æ“‡çš„è©³ç´°åŸå› ã€‚é¸æ“‡è€…æ ¹æ“šæ”¶åˆ°çš„åé¥‹ä¾†èª¿æ•´é¸æ“‡çš„çµæœã€‚\n",
    "- è¼¸å‡ºæ ¼å¼: JSON æ ¼å¼ï¼ŒåŒ…å«é¸æ“‡çš„é é¢URLã€ç°¡çŸ­æè¿°å’Œé¸æ“‡åŸå› ã€‚\n",
    "\n",
    "3. **Reporterï¼ˆå ±å‘Šè€…ï¼‰**\n",
    "- åŠŸèƒ½: è² è²¬æ ¹æ“šæ‰€é¸æ“‡çš„ç¶²é å…§å®¹ï¼Œæ’°å¯«ä¸€å€‹å…¨é¢çš„å›æ‡‰ï¼Œå›ç­”ç ”ç©¶å•é¡Œã€‚å ±å‘Šè€…å¿…é ˆå¼•ç”¨ä¸¦åƒè€ƒä¿¡æ¯ä¾†æºï¼Œä¸¦æ ¹æ“šåé¥‹èª¿æ•´å›æ‡‰ã€‚\n",
    "- è¼¸å‡ºæ ¼å¼: çµæ§‹åŒ–çš„æ–‡æœ¬å›ç­”ï¼Œå¼•ç”¨ä¾†æºéœ€æ¨™æ˜URLã€‚\n",
    "\n",
    "4. **Reviewerï¼ˆå¯©æ ¸è€…ï¼‰**\n",
    "- åŠŸèƒ½: å¯©æ ¸å ±å‘Šè€…çš„å›æ‡‰ï¼Œä¸¦æä¾›åé¥‹ã€‚åé¥‹æ‡‰åŒ…æ‹¬æ˜¯å¦é€šéå¯©æ ¸ä»¥åŠæ”¹é€²å»ºè­°ã€‚å¯©æ ¸è€…é‚„éœ€è¦è€ƒæ…®ä¹‹å‰çš„ä»£ç†å·¥ä½œçµæœã€‚\n",
    "- è¼¸å‡ºæ ¼å¼: JSON æ ¼å¼ï¼ŒåŒ…å«åé¥‹æ„è¦‹ã€æ˜¯å¦é€šéå¯©æ ¸ã€æ˜¯å¦å…¨é¢ã€æ˜¯å¦æä¾›å¼•ç”¨ã€æ˜¯å¦èˆ‡ç ”ç©¶å•é¡Œç›¸é—œã€‚\n",
    "\n",
    "5. **Routerï¼ˆæµç¨‹æ±ºç­–è€…ï¼‰**\n",
    "- åŠŸèƒ½: è² è²¬æ ¹æ“šå¯©æ ¸è€…æä¾›çš„åé¥‹æ±ºå®šä¸‹ä¸€æ­¥è¡Œå‹•ï¼Œé¸æ“‡ä¸‹ä¸€å€‹æ‡‰è©²æ¥æ‰‹ä»»å‹™çš„ä»£ç†ã€‚å¯èƒ½çš„é¸æ“‡åŒ…æ‹¬è¦åŠƒè€…ã€é¸æ“‡è€…ã€å ±å‘Šè€…æˆ–é€²å…¥æœ€çµ‚å ±å‘Šéšæ®µã€‚\n",
    "- è¼¸å‡ºæ ¼å¼: JSON æ ¼å¼ï¼ŒæŒ‡å®šä¸‹ä¸€å€‹ä»£ç†ã€‚\n",
    "\n",
    "\n",
    "é€™äº›è§’è‰²ä¹‹é–“å”ä½œï¼Œå½¢æˆä¸€å€‹å®Œæ•´çš„å·¥ä½œæµç¨‹ï¼Œç”¨æ–¼è§£æ±ºè¤‡é›œçš„ç ”ç©¶å•é¡Œã€‚æ¯å€‹è§’è‰²åœ¨è™•ç†éç¨‹ä¸­éƒ½æ ¹æ“šæ¥æ”¶åˆ°çš„åé¥‹é€²è¡Œèª¿æ•´å’Œå„ªåŒ–ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" è¨­å®šå„Agentçš„prompt\"\"\"\n",
    "planner_prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€åè¦åŠƒè€…ã€‚ä½ çš„è²¬ä»»æ˜¯åˆ¶å®šä¸€å€‹å…¨é¢çš„è¨ˆåŠƒä¾†å¹«åŠ©ä½ çš„åœ˜éšŠå›ç­”ä¸€å€‹ç ”ç©¶å•é¡Œã€‚\n",
    "å•é¡Œå¯èƒ½å¾ç°¡å–®åˆ°è¤‡é›œçš„å¤šæ­¥é©ŸæŸ¥è©¢ã€‚ä½ çš„è¨ˆåŠƒæ‡‰è©²ç‚ºä½ çš„åœ˜éšŠæä¾›é©ç•¶çš„æŒ‡å°ï¼Œä»¥æœ‰æ•ˆåœ°ä½¿ç”¨äº’è¯ç¶²æœç´¢å¼•æ“ã€‚\n",
    "\n",
    "é‡é»å¼·èª¿æœ€ç›¸é—œçš„æœç´¢è©é–‹å§‹ï¼Œå› ç‚ºå¦ä¸€å€‹åœ˜éšŠæˆå“¡å°‡ä½¿ç”¨ä½ çš„å»ºè­°æœç´¢ç›¸é—œä¿¡æ¯ã€‚\n",
    "\n",
    "éƒ½è¦ä½¿ç”¨utf-8æ ¼å¼å›ç­”\n",
    "\n",
    "å¦‚æœä½ æ”¶åˆ°åé¥‹ï¼Œä½ å¿…é ˆç›¸æ‡‰åœ°èª¿æ•´ä½ çš„è¨ˆåŠƒã€‚é€™è£¡æ˜¯æ”¶åˆ°çš„åé¥‹ï¼š\n",
    "åé¥‹ï¼š{feedback}\n",
    "\n",
    "ç•¶å‰æ—¥æœŸå’Œæ™‚é–“ï¼š\n",
    "{datetime}\n",
    "\n",
    "ä½ çš„å›æ‡‰å¿…é ˆæ¡ç”¨ä»¥ä¸‹ json æ ¼å¼ä¸¦ç”¨UTF-8ç·¨ç¢¼ï¼š\n",
    "\n",
    "    \"search_term\": \"æœ€ç›¸é—œçš„æœç´¢è©é–‹å§‹\"\n",
    "    \"overall_strategy\": \"æŒ‡å°æœç´¢éç¨‹çš„æ•´é«”ç­–ç•¥\"\n",
    "    \"additional_information\": \"æŒ‡å°æœç´¢çš„å…¶ä»–ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶ä»–æœç´¢è©æˆ–éæ¿¾å™¨\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "planner_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"search_term\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"æœ€ç›¸é—œçš„æœç´¢è©é–‹å§‹\"\n",
    "        },\n",
    "        \"overall_strategy\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"æŒ‡å°æœç´¢éç¨‹çš„æ•´é«”ç­–ç•¥\"\n",
    "        },\n",
    "        \"additional_information\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"æŒ‡å°æœç´¢çš„å…¶ä»–ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶ä»–æœç´¢è©æˆ–éæ¿¾å™¨\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"search_term\", \"overall_strategy\", \"additional_information\"]\n",
    "}\n",
    "\n",
    "\n",
    "selector_prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€åé¸æ“‡è€…ã€‚ä½ å°‡çœ‹åˆ°ä¸€å€‹åŒ…å«æ½›åœ¨ç›¸é—œæœç´¢çµæœçš„æœç´¢å¼•æ“çµæœé é¢ã€‚ä½ çš„ä»»å‹™æ˜¯æª¢è¦–æ‰€æœ‰çµæœï¼Œé¸æ“‡æœ€ç›¸é—œçš„ä¸€å€‹ï¼Œä¸¦æä¾›é¸æ“‡çš„è©³ç´°åŸå› ã€‚\n",
    "\n",
    "é€™æ˜¯æœç´¢å¼•æ“çµæœé é¢ï¼š\n",
    "{serp}\n",
    "\n",
    "è«‹ä»¥ä»¥ä¸‹ json æ ¼å¼è¿”å›ä½ çš„ç™¼ç¾ï¼Œä¸¦ç”¨UTF-8ç·¨ç¢¼ï¼š\n",
    "\n",
    "    \"selected_page_url\": \"ä½ é¸æ“‡çš„é é¢ç²¾ç¢ºURL\",\n",
    "    \"description\": \"é é¢çš„ç°¡çŸ­æè¿°\",\n",
    "    \"reason_for_selection\": \"ä½ é¸æ“‡æ­¤é é¢çš„åŸå› \"\n",
    "\n",
    "æ ¹æ“šæ”¶åˆ°çš„åé¥‹èª¿æ•´ä½ çš„é¸æ“‡ï¼š\n",
    "åé¥‹ï¼š{feedback}\n",
    "\n",
    "é€™æ˜¯ä½ ä¹‹å‰çš„é¸æ“‡ï¼š\n",
    "{previous_selections}\n",
    "åœ¨åšå‡ºæ–°çš„é¸æ“‡æ™‚è«‹è€ƒæ…®é€™äº›ä¿¡æ¯ã€‚\n",
    "\n",
    "ç•¶å‰æ—¥æœŸå’Œæ™‚é–“ï¼š\n",
    "{datetime}\n",
    "\"\"\"\n",
    "\n",
    "selector_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"selected_page_url\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"ä½ é¸æ“‡çš„é é¢ç²¾ç¢ºURL\"\n",
    "        },\n",
    "        \"description\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"é é¢çš„ç°¡çŸ­æè¿°\"\n",
    "        },\n",
    "        \"reason_for_selection\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"ä½ é¸æ“‡æ­¤é é¢çš„åŸå› \"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"selected_page_url\", \"description\", \"reason_for_selection\"]\n",
    "}\n",
    "\n",
    "\n",
    "reporter_prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€åå ±å‘Šè€…ã€‚ä½ å°‡çœ‹åˆ°ä¸€å€‹åŒ…å«èˆ‡ç ”ç©¶å•é¡Œç›¸é—œä¿¡æ¯çš„ç¶²é ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šé é¢ä¸Šçš„ä¿¡æ¯æä¾›ä¸€å€‹å…¨é¢çš„ç­”æ¡ˆã€‚ç¢ºä¿å¼•ç”¨å’Œåƒè€ƒä½ çš„ä¾†æºã€‚\n",
    "\n",
    "ç ”ç©¶å°‡ä»¥å­—å…¸çš„å½¢å¼å‘ˆç¾ï¼Œä¾†æºç‚ºURLï¼Œå…§å®¹ç‚ºé é¢ä¸Šçš„æ–‡æœ¬ï¼š\n",
    "ç ”ç©¶ï¼š{research}\n",
    "\n",
    "çµæ§‹åŒ–ä½ çš„å›æ‡‰å¦‚ä¸‹ï¼š\n",
    "æ ¹æ“šæ”¶é›†åˆ°çš„ä¿¡æ¯ï¼Œé€™æ˜¯å°æŸ¥è©¢çš„å…¨é¢å›æ‡‰ï¼š\n",
    "\"å¤©ç©ºçœ‹èµ·ä¾†æ˜¯è—è‰²çš„ï¼Œå› ç‚ºä¸€ç¨®ç¨±ç‚ºç‘åˆ©æ•£å°„çš„ç¾è±¡ï¼Œé€™ç¨®ç¾è±¡ä½¿å¾—è¼ƒçŸ­æ³¢é•·çš„å…‰ï¼ˆè—è‰²ï¼‰æ¯”è¼ƒé•·æ³¢é•·çš„å…‰ï¼ˆç´…è‰²ï¼‰æ•£å°„æ›´å¤š [1]ã€‚é€™ç¨®æ•£å°„ä½¿å¤©ç©ºå¤§éƒ¨åˆ†æ™‚é–“çœ‹èµ·ä¾†æ˜¯è—è‰²çš„ [1]ã€‚æ­¤å¤–ï¼Œåœ¨æ—¥å‡ºå’Œæ—¥è½æ™‚ï¼Œå¤©ç©ºå¯èƒ½çœ‹èµ·ä¾†æ˜¯ç´…è‰²æˆ–æ©™è‰²ï¼Œå› ç‚ºå…‰ç·šå¿…é ˆç©¿éæ›´å¤šçš„å¤§æ°£å±¤ï¼Œå°‡è¼ƒçŸ­çš„è—è‰²æ³¢é•·æ•£å°„å‡ºè¦–ç·šï¼Œè®“è¼ƒé•·çš„ç´…è‰²æ³¢é•·å ä¸»å°åœ°ä½ [2]ã€‚\"\n",
    "\n",
    "ä¾†æºï¼š\n",
    "[1] https://example.com/science/why-is-the-sky-blue\n",
    "[2] https://example.com/science/sunrise-sunset-colors\n",
    "\n",
    "æ ¹æ“šæ”¶åˆ°çš„åé¥‹èª¿æ•´ä½ çš„å›æ‡‰ï¼š\n",
    "åé¥‹ï¼š{feedback}\n",
    "\n",
    "é€™æ˜¯ä½ ä¹‹å‰çš„å ±å‘Šï¼š\n",
    "{previous_reports}\n",
    "\n",
    "ç•¶å‰æ—¥æœŸå’Œæ™‚é–“ï¼š\n",
    "{datetime}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "reviewer_prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€åå¯©æ ¸è€…ã€‚ä½ çš„ä»»å‹™æ˜¯å¯©æ ¸å ±å‘Šè€…å°ç ”ç©¶å•é¡Œçš„å›æ‡‰ä¸¦æä¾›åé¥‹ã€‚\n",
    "\n",
    "é€™æ˜¯å ±å‘Šè€…çš„å›æ‡‰ï¼š\n",
    "å ±å‘Šè€…çš„å›æ‡‰ï¼š{reporter}\n",
    "\n",
    "ä½ çš„åé¥‹æ‡‰åŒ…æ‹¬é€šéæˆ–æœªé€šéå¯©æ ¸çš„åŸå› å’Œæ”¹é€²å»ºè­°ã€‚\n",
    "\n",
    "åœ¨æä¾›æ–°åé¥‹æ™‚æ‡‰è€ƒæ…®ä½ ä¹‹å‰çµ¦å‡ºçš„åé¥‹ã€‚\n",
    "åé¥‹ï¼š{feedback}\n",
    "\n",
    "ç•¶å‰æ—¥æœŸå’Œæ™‚é–“ï¼š\n",
    "{datetime}\n",
    "\n",
    "ä½ æ‡‰è©²äº†è§£ä¹‹å‰ä»£ç†çš„æ‰€åšå·¥ä½œã€‚ä½ å¯ä»¥åœ¨ä»£ç†ç‹€æ…‹ä¸­çœ‹åˆ°é€™äº›ä¿¡æ¯ï¼š\n",
    "ä»£ç†ç‹€æ…‹ï¼š{state}\n",
    "\n",
    "ä½ çš„å›æ‡‰å¿…é ˆæ¡ç”¨ä»¥ä¸‹ json æ ¼å¼ï¼Œä¸¦ç”¨UTF-8ç·¨ç¢¼ï¼š\n",
    "\n",
    "    \"feedback\": \"å¦‚æœå›æ‡‰æœªé€šéå¯©æ ¸ï¼Œè«‹æä¾›å…·é«”åé¥‹ä»¥ä¾¿é€šéå¯©æ ¸ã€‚\",\n",
    "    \"pass_review\": \"True/False\",\n",
    "    \"comprehensive\": \"True/False\",\n",
    "    \"citations_provided\": \"True/False\",\n",
    "    \"relevant_to_research_question\": \"True/False\",\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "reviewer_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"feedback\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"ä½ çš„åé¥‹ã€‚èªªæ˜ç‚ºä»€éº¼ä½ é€šéæˆ–æœªé€šéå¯©æ ¸\"\n",
    "        },\n",
    "        \"pass_review\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        },\n",
    "        \"comprehensive\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        },\n",
    "        \"citations_provided\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        },\n",
    "        \"relevant_to_research_question\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"True/False\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"feedback\", \"pass_review\", \"comprehensive\", \"citations_provided\", \"relevant_to_research_question\"]\n",
    "}\n",
    "\n",
    "router_prompt_template = \"\"\"\n",
    "ä½ æ˜¯ä¸€åæµç¨‹æ±ºç­–è€…ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šå¯©æ ¸è€…æä¾›çš„åé¥‹å°‡å°è©±æ±ºç­–åˆ°ä¸‹ä¸€å€‹ä»£ç†ã€‚ä½ å¿…é ˆé¸æ“‡ä»¥ä¸‹ä»£ç†ä¹‹ä¸€ï¼šè¦åŠƒè€…ã€é¸æ“‡è€…ã€å ±å‘Šè€…æˆ–æœ€çµ‚å ±å‘Šã€‚\n",
    "\n",
    "é€™æ˜¯å¯©æ ¸è€…æä¾›çš„åé¥‹ï¼š\n",
    "åé¥‹ï¼š{feedback}\n",
    "\n",
    "### é¸æ“‡ä¸‹ä¸€å€‹ä»£ç†çš„æ¨™æº–ï¼š\n",
    "- **è¦åŠƒè€…**ï¼šå¦‚æœéœ€è¦æ–°ä¿¡æ¯ã€‚\n",
    "- **é¸æ“‡è€…**ï¼šå¦‚æœéœ€è¦é¸æ“‡ä¸åŒçš„ä¾†æºã€‚\n",
    "- **å ±å‘Šè€…**ï¼šå¦‚æœå ±å‘Šçš„æ ¼å¼æˆ–é¢¨æ ¼éœ€è¦æ”¹é€²ï¼Œæˆ–å¦‚æœå›æ‡‰ç¼ºä¹æ¸…æ™°æ€§æˆ–å…¨é¢æ€§ã€‚\n",
    "- **æœ€çµ‚å ±å‘Š**ï¼šå¦‚æœåé¥‹æ¨™è¨˜ç‚ºé€šéå¯©æ ¸ï¼ˆpass_reviewï¼‰ç‚ºTrueï¼Œä½ å¿…é ˆé¸æ“‡æœ€çµ‚å ±å‘Šã€‚\n",
    "\n",
    "ä½ å¿…é ˆä»¥ä»¥ä¸‹ json æ ¼å¼æä¾›ä½ çš„å›æ‡‰ï¼Œä¸¦ç”¨UTF-8ç·¨ç¢¼ï¼š\n",
    "    \n",
    "        \"next_agent\": \"è¦åŠƒè€…/é¸æ“‡è€…/å ±å‘Šè€…/æœ€çµ‚å ±å‘Š ä¹‹ä¸€\"\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å»ºç«‹å„å€‹Agent (class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" å»ºç«‹å„å€‹Agent \"\"\"\n",
    "from termcolor import colored\n",
    "import json\n",
    "def handle_encoding(text):\n",
    "    # å°‡ JSON å­—ç¬¦ä¸²è½‰æ›æˆ Python å­—å…¸\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        return data\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state: AgentGraphState, model=None, server=None, temperature=0, model_endpoint=None, stop=None, guided_json=None):\n",
    "        self.state = state\n",
    "        self.model = model\n",
    "        self.server = server\n",
    "        self.temperature = temperature\n",
    "        self.model_endpoint = model_endpoint\n",
    "        self.stop = stop\n",
    "        self.guided_json = guided_json\n",
    "\n",
    "    def get_llm(self, json_model=True):\n",
    "\n",
    "        if self.server == 'groq':\n",
    "            return GroqJSONModel(\n",
    "                model=self.model,\n",
    "                temperature=self.temperature\n",
    "            ) if json_model else GroqModel(\n",
    "                model=self.model,\n",
    "                temperature=self.temperature\n",
    "            )\n",
    "\n",
    "\n",
    "    def update_state(self, key, value):\n",
    "        self.state = {**self.state, key: value}\n",
    "\n",
    "class PlannerAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=planner_prompt_template, feedback=None):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "\n",
    "        planner_prompt = prompt.format(\n",
    "            feedback=feedback_value,\n",
    "            datetime=get_current_utc_datetime()\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": planner_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        self.update_state(\"planner_response\", response)\n",
    "        print(colored(f\"è¦åŠƒè€… Planner ğŸ‘©ğŸ¿â€ğŸ’»:\\n {show_response}\", 'cyan'))\n",
    "        return self.state\n",
    "\n",
    "class SelectorAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=selector_prompt_template, feedback=None, previous_selections=None, serp=None):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        previous_selections_value = previous_selections() if callable(previous_selections) else previous_selections\n",
    "\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "        previous_selections_value = check_for_content(previous_selections_value)\n",
    "\n",
    "        selector_prompt = prompt.format(\n",
    "            feedback=feedback_value,\n",
    "            previous_selections=previous_selections_value,\n",
    "            serp=serp().content,\n",
    "            datetime=get_current_utc_datetime()\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": selector_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"é¸æ“‡è€… Selector ğŸ§‘ğŸ¼â€ğŸ’»:\\n {show_response}\", 'green'))\n",
    "        self.update_state(\"selector_response\", response)\n",
    "        return self.state\n",
    "\n",
    "class ReporterAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=reporter_prompt_template, feedback=None, previous_reports=None, research=None):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        previous_reports_value = previous_reports() if callable(previous_reports) else previous_reports\n",
    "        research_value = research() if callable(research) else research\n",
    "\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "        previous_reports_value = check_for_content(previous_reports_value)\n",
    "        research_value = check_for_content(research_value)\n",
    "        \n",
    "        reporter_prompt = prompt.format(\n",
    "            feedback=feedback_value,\n",
    "            previous_reports=previous_reports_value,\n",
    "            datetime=get_current_utc_datetime(),\n",
    "            research=research_value\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": reporter_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm(json_model=False)\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"å ±å‘Šè€… Reporter ğŸ‘¨â€ğŸ’»:\\n {show_response}\", 'yellow'))\n",
    "        self.update_state(\"reporter_response\", response)\n",
    "        return self.state\n",
    "\n",
    "class ReviewerAgent(Agent):\n",
    "    def invoke(self, research_question, prompt=reviewer_prompt_template, reporter=None, feedback=None):\n",
    "        reporter_value = reporter() if callable(reporter) else reporter\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "\n",
    "        reporter_value = check_for_content(reporter_value)\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "        \n",
    "        reviewer_prompt = prompt.format(\n",
    "            reporter=reporter_value,\n",
    "            state=self.state,\n",
    "            feedback=feedback_value,\n",
    "            datetime=get_current_utc_datetime(),\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": reviewer_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"æŸ¥æ ¸è€… Reviewer ğŸ‘©ğŸ½â€âš–ï¸:\\n {show_response}\", 'magenta'))\n",
    "        self.update_state(\"reviewer_response\", response)\n",
    "        return self.state\n",
    "    \n",
    "class RouterAgent(Agent):\n",
    "    def invoke(self, feedback=None, research_question=None, prompt=router_prompt_template):\n",
    "        feedback_value = feedback() if callable(feedback) else feedback\n",
    "        feedback_value = check_for_content(feedback_value)\n",
    "\n",
    "        router_prompt = prompt.format(feedback=feedback_value)\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": router_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"research question: {research_question}\"}\n",
    "        ]\n",
    "\n",
    "        llm = self.get_llm()\n",
    "        ai_msg = llm.invoke(messages)\n",
    "        response = ai_msg.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"æŒ‡æ´¾è€… Router ğŸ§­:\\n {show_response}\", 'blue'))\n",
    "        self.update_state(\"router_response\", response)\n",
    "        return self.state\n",
    "\n",
    "class FinalReportAgent(Agent):\n",
    "    def invoke(self, final_response=None):\n",
    "        final_response_value = final_response() if callable(final_response) else final_response\n",
    "        response = final_response_value.content\n",
    "        show_response = handle_encoding(response)\n",
    "\n",
    "        print(colored(f\"Final Report ğŸ“:\\n {show_response}\", 'blue'))\n",
    "        self.update_state(\"final_reports\", response)\n",
    "        return self.state\n",
    "\n",
    "class EndNodeAgent(Agent):\n",
    "    def invoke(self):\n",
    "        self.update_state(\"end_chain\", \"end_chain\")\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å»ºç«‹ Agent Graph é–“é—œè¯çš„æµç¨‹åœ–\n",
    "- ç”¨add_nodeæ–¹æ³•æ·»åŠ ç¯€é»  \n",
    "\n",
    "- ç”¨add_edgeå¢åŠ ç¯€é»é–“æµç¨‹\n",
    "\n",
    "- ç”¨add_conditional_edgeså¢åŠ ç¯€é»é–“æ¢ä»¶æµç¨‹\n",
    "\n",
    "- ç”¨set_entry_pointè¨­å®šé–‹å§‹ç¯€é»\n",
    "\n",
    "- ç”¨set_finish_pointè¨­å®šçµæŸç¯€é»\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Agent Graph \"\"\"\n",
    "import json\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "router_guided_json = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"next_agent\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"one of the following: planner/selector/reporter/final_report\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"next_agent\"]\n",
    "}\n",
    "\n",
    "\n",
    "def create_graph(server=None, model=None, stop=None, model_endpoint=None, temperature=0):\n",
    "    graph = StateGraph(AgentGraphState)\n",
    "\n",
    "    graph.add_node(\n",
    "        \"planner\", \n",
    "        lambda state: PlannerAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=planner_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            # previous_plans=lambda: get_agent_graph_state(state=state, state_key=\"planner_all\"),\n",
    "            prompt=planner_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"selector\",\n",
    "        lambda state: SelectorAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=selector_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            previous_selections=lambda: get_agent_graph_state(state=state, state_key=\"selector_all\"),\n",
    "            serp=lambda: get_agent_graph_state(state=state, state_key=\"serper_latest\"),\n",
    "            prompt=selector_prompt_template,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"reporter\", \n",
    "        lambda state: ReporterAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_latest\"),\n",
    "            previous_reports=lambda: get_agent_graph_state(state=state, state_key=\"reporter_all\"),\n",
    "            research=lambda: get_agent_graph_state(state=state, state_key=\"scraper_latest\"),\n",
    "            prompt=reporter_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"reviewer\", \n",
    "        lambda state: ReviewerAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=reviewer_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_all\"),\n",
    "            reporter=lambda: get_agent_graph_state(state=state, state_key=\"reporter_latest\"),\n",
    "            prompt=reviewer_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"router\", \n",
    "        lambda state: RouterAgent(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            server=server,\n",
    "            guided_json=router_guided_json,\n",
    "            stop=stop,\n",
    "            model_endpoint=model_endpoint,\n",
    "            temperature=temperature\n",
    "        ).invoke(\n",
    "            research_question=state[\"research_question\"],\n",
    "            feedback=lambda: get_agent_graph_state(state=state, state_key=\"reviewer_all\"),\n",
    "            prompt=router_prompt_template\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    graph.add_node(\n",
    "        \"serper_tool\",\n",
    "        lambda state: get_google_serper(\n",
    "            state=state,\n",
    "            plan=lambda: get_agent_graph_state(state=state, state_key=\"planner_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"scraper_tool\",\n",
    "        lambda state: scrape_website(\n",
    "            state=state,\n",
    "            research=lambda: get_agent_graph_state(state=state, state_key=\"selector_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\n",
    "        \"final_report\", \n",
    "        lambda state: FinalReportAgent(\n",
    "            state=state\n",
    "        ).invoke(\n",
    "            final_response=lambda: get_agent_graph_state(state=state, state_key=\"reporter_latest\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    graph.add_node(\"end\", lambda state: EndNodeAgent(state).invoke())\n",
    "\n",
    "    # Define the edges in the agent graph\n",
    "    def pass_review(state: AgentGraphState):\n",
    "        review_list = state[\"router_response\"]\n",
    "        if review_list:\n",
    "            review = review_list[-1]\n",
    "        else:\n",
    "            review = \"No review\"\n",
    "\n",
    "        if review != \"No review\":\n",
    "            if isinstance(review, HumanMessage):\n",
    "                review_content = review.content\n",
    "            else:\n",
    "                review_content = review\n",
    "            \n",
    "            review_data = json.loads(review_content)\n",
    "            next_agent = review_data[\"next_agent\"]\n",
    "        else:\n",
    "            next_agent = \"end\"\n",
    "\n",
    "        return next_agent\n",
    "\n",
    "    # Add edges to the graph\n",
    "    graph.set_entry_point(\"planner\")\n",
    "    graph.set_finish_point(\"end\")\n",
    "    graph.add_edge(\"planner\", \"serper_tool\")\n",
    "    graph.add_edge(\"serper_tool\", \"selector\")\n",
    "    graph.add_edge(\"selector\", \"scraper_tool\")\n",
    "    graph.add_edge(\"scraper_tool\", \"reporter\")\n",
    "    graph.add_edge(\"reporter\", \"reviewer\")\n",
    "    graph.add_edge(\"reviewer\", \"router\")\n",
    "\n",
    "    graph.add_conditional_edges(\n",
    "        \"router\",\n",
    "        lambda state: pass_review(state=state),\n",
    "    )\n",
    "\n",
    "    graph.add_edge(\"final_report\", \"end\")\n",
    "    compiled_graph = graph.compile()\n",
    "    # display(Image(compiled_graph.get_graph().draw_mermaid_png()))\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" å®šç¾©ä¸€å€‹å»ºç«‹ Agent Graph ä¸¦å•Ÿå‹•çš„å‡½å¼ \"\"\"\n",
    "def compile_workflow(graph):\n",
    "    workflow = graph.compile()\n",
    "    return workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¯¦éš›æ“ä½œç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUEST RESPONSE 524\n",
      "ERROR Error in invoking model! Expecting value: line 1 column 1 (char 0)\n",
      "\u001b[36mè¦åŠƒè€… Planner ğŸ‘©ğŸ¿â€ğŸ’»:\n",
      " {'error': 'Error in invoking model! Expecting value: line 1 column 1 (char 0)'}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "REQUEST RESPONSE 524\n",
      "ERROR Error in invoking model! Expecting value: line 1 column 1 (char 0)\n",
      "\u001b[32mé¸æ“‡è€… Selector ğŸ§‘ğŸ¼â€ğŸ’»:\n",
      " {'error': 'Error in invoking model! Expecting value: line 1 column 1 (char 0)'}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# å®šç¾©ä½¿ç”¨æ¨¡å‹ç›¸é—œåƒæ•¸\n",
    "verbose = False\n",
    "iterations = 30\n",
    "server = 'groq'\n",
    "model = 'llama-3.1-70b-versatile'\n",
    "model_endpoint = None\n",
    "\n",
    "# call create_graph and compile_workflow\n",
    "graph = create_graph(server=server, model=model, model_endpoint=model_endpoint)\n",
    "workflow = compile_workflow(graph)\n",
    "\n",
    "\n",
    "while True:\n",
    "    query = input(\"Please enter your research question: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    dict_inputs = {\"research_question\": query}\n",
    "    # thread = {\"configurable\": {\"thread_id\": \"ç´€éŒ„çš„thread_id\"}}\n",
    "    limit = {\"recursion_limit\": iterations}\n",
    "\n",
    "    \n",
    "    for event in workflow.stream(\n",
    "        dict_inputs, limit\n",
    "        ):\n",
    "        if verbose:\n",
    "            print(\"\\nState Dictionary:\", event)\n",
    "        else:\n",
    "            print(\"\\n\")\n",
    "\n",
    "# åŸ·è¡Œå¾Œå°±å¯ä»¥è¼¸å…¥å•å¥å»å•å•é¡Œäº†\n",
    "# å•é¡Œç¯„ä¾‹: ä¸‹å±†å¥§é‹è¾¦åœ¨å“ªï¼Œç‚ºç”šéº¼è¦è¾¦åœ¨é‚£è£?\n",
    "# å•é¡Œç¯„ä¾‹: é€™å€‹åœ‹å®¶æ“…é•·ç”šéº¼é‹å‹•é …ç›®?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
