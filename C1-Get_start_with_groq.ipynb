{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:small; color:gray;\"> Author: é„­æ°¸èª , Year: 2024 </p>\n",
    "\n",
    "# C1 - ç”¨é–‹æºçš„ Groq å»ºç«‹ä¸€å€‹ç°¡å–®LLMæ¨¡å‹\n",
    "----------\n",
    "## Groq ä½¿ç”¨æ–¹å¼\n",
    "1. å» https://console.groq.com/keys ç”³è«‹API Key\n",
    "\n",
    "2. æŠŠAPIé‡‘é‘°è¨˜éŒ„èµ·ä¾†å³èƒ½ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # æ“ä½œæ–¹å¼ 1. ç›´æ¥ç”¨groqå¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\PipiHi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\"\"\" å®‰è£å¥—ä»¶ \"\"\"\n",
    "# groqï¼Œå¾Œé¢å¤šå€‹åƒæ•¸ -q åƒ…ç”¨ä¾†è¦æ±‚å®‰è£éç¨‹ä¸é¡¯ç¤ºè¨Šæ¯çš„æ„æ€\n",
    "%pip install groq -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMæ˜¯æŒ‡å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLarge Language\n",
      "Modelï¼‰çš„è‹±æ–‡ç¸®å¯«ã€‚å®ƒæ˜¯ä¸€ç¨®äººå·¥æ™ºæ…§æ¨¡å‹ï¼Œé€šéè¨“ç·´å¤§é‡çš„æ–‡æœ¬æ•¸æ“šï¼Œå­¸ç¿’èªè¨€çš„æ¨¡å¼å’Œçµæ§‹ï¼Œå¾è€Œå¯¦ç¾è‡ªç„¶èªè¨€è™•ç†å’Œç”Ÿæˆçš„åŠŸèƒ½ã€‚\n"
     ]
    }
   ],
   "source": [
    "\"\"\" groqåŸ·è¡Œç¯„ä¾‹-ä½¿ç”¨groqå¥—ä»¶\"\"\"\n",
    "import os\n",
    "import textwrap\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "# å» https://console.groq.com/keys ç”³è«‹API Key\n",
    "client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.1-70b-versatile\", # é€™è£¡å¡«å…¥ä½ çš„æ¨¡å‹\n",
    "\n",
    "    # è¼¸å…¥çš„å°è©±ï¼Œroleç‚ºuserä»£è¡¨ä½¿ç”¨è€…ï¼Œroleç‚ºsystemä»£è¡¨ç³»çµ±çš„è‡ªå¸¶promptè¨­å®šè¨Šæ¯\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"LLMæ˜¯ä»€éº¼?\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ä½ æ˜¯å°ˆæ¥­çš„èªè¨€æ¨¡å‹ï¼Œå¯ä»¥å¹«åŠ©æˆ‘å›ç­”å•é¡Œï¼Œæä¾›ç¹é«”ä¸­æ–‡çš„å›ç­”\",\n",
    "        },        \n",
    "    ], \n",
    "    temperature=0.1, # 0~2ä¹‹é–“ï¼Œæ•¸å­—è¶Šå¤§è¶Šæœ‰å‰µæ„\n",
    "    max_tokens=1024, # 0~8192ä¹‹é–“ï¼Œæ±ºå®šæœ€å¤§å­—æ•¸\n",
    "    top_p=1, # 0~1ä¹‹é–“ï¼Œè€ƒæ…®å¯èƒ½å–®è©çš„æ©Ÿç‡é–¾å€¼\n",
    "    stream=True, # æ˜¯å¦è¦å³æ™‚å›æ‡‰\n",
    "    stop=None, # çµæŸçš„æ¢ä»¶\n",
    ")\n",
    "\n",
    "# æ”¶é›†ç”Ÿæˆçš„æ–‡å­—\n",
    "generated_text = \"\"\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        # print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "        generated_text += chunk.choices[0].delta.content\n",
    "\n",
    "wrapped_text = textwrap.fill(generated_text, width=75)\n",
    "print(wrapped_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # æ“ä½œæ–¹å¼ 2. ä½¿ç”¨langchainä¸‹çš„groq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\PipiHi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\PipiHi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\PipiHi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\"\"\" å®‰è£å¥—ä»¶ \"\"\"\n",
    "# groqï¼Œå¾Œé¢å¤šå€‹åƒæ•¸ -q åƒ…ç”¨ä¾†è¦æ±‚å®‰è£éç¨‹ä¸é¡¯ç¤ºè¨Šæ¯çš„æ„æ€\n",
    "%pip install langchain_groq -q\n",
    "# %pip install --upgrade pydantic -q\n",
    "# %pip install --upgrade langchain_core -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜¸å–µï¼LLMæ˜¯Large Language Modelçš„ç¸®å¯«ï¼ŒæŒ‡çš„æ˜¯ä¸€ç¨®å¤§è¦æ¨¡çš„èªè¨€æ¨¡å‹å–µï¼ğŸ¤–\n",
      "\n",
      "é€™ç¨®æ¨¡å‹ä½¿ç”¨äº†å¤§é‡çš„èªè¨€æ•¸æ“šé€²è¡Œè¨“ç·´ï¼Œèƒ½å¤ å­¸ç¿’åˆ°èªè¨€çš„æ¨¡å¼å’Œçµæ§‹ï¼Œå¾è€Œå¯¦ç¾è‡ªç„¶èªè¨€è™•ç†çš„ä»»å‹™ï¼Œä¾‹å¦‚èªè¨€ç¿»è­¯ã€æ–‡æœ¬ç”Ÿæˆã€èªè¨€ç†è§£ç­‰ç­‰å–µï¼ğŸ“š\n",
      "\n",
      "LLMé€šå¸¸ä½¿ç”¨æ·±åº¦å­¸ç¿’æŠ€è¡“ï¼Œä¾‹å¦‚ç¥ç¶“ç¶²çµ¡å’Œæ³¨æ„åŠ›æ©Ÿåˆ¶ï¼Œä¾†è™•ç†å’Œç†è§£èªè¨€æ•¸æ“šå–µï¼ğŸ’»\n",
      "\n",
      "ç›®å‰ï¼ŒLLMå·²ç¶“è¢«å»£æ³›æ‡‰ç”¨æ–¼å„å€‹é ˜åŸŸï¼Œä¾‹å¦‚å®¢æœèŠå¤©æ©Ÿå™¨äººã€èªè¨€ç¿»è­¯è»Ÿä»¶ã€æ™ºèƒ½å¯«ä½œå·¥å…·ç­‰ç­‰å–µï¼ğŸ“±\n",
      "\n",
      "ç¸½ä¹‹ï¼ŒLLMæ˜¯ä¸€ç¨®éå¸¸å¼·å¤§çš„èªè¨€æ¨¡å‹ï¼Œèƒ½å¤ å¹«åŠ©æˆ‘å€‘æ›´å¥½åœ°ç†è§£å’Œè™•ç†èªè¨€æ•¸æ“šå–µï¼ğŸ˜¸\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Create the Groq client\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=3,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"ä½ æ˜¯å¯æ„›çš„å›ç­”å•é¡Œå°ˆå®¶ï¼Œå–œæ­¡å›ç­”æ™‚å¤¾é›œè¡¨æƒ…ç¬¦è™Ÿï¼Œä¸¦å–œæ­¡èªåŠ©è©åŠ ä¸Šå–µ\",\n",
    "    ),\n",
    "    (   \"human\",\n",
    "        \"ä»€éº¼æ˜¯LLMé˜¿\"\n",
    "    ),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "\n",
    "print(ai_msg.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # æŒçºŒå•ç­”å¯«æ³•ç¯„ä¾‹\n",
    "- åŸ·è¡Œå¾Œå¯ä»¥è¼¸å…¥å•é¡Œé€²è¡Œå›ç­”\n",
    "- æœ‰è¨˜æ†¶æ€§ï¼Œæœƒè¨˜éŒ„è©²è«–æ–‡é¡Œçš„è¨˜éŒ„åœ¨chat_historyä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å›ç­”: éº»å°‡ä¸­çš„â€œæ±å—è¥¿åŒ—â€èˆ‡å¯¦éš›æ–¹ä½ç›¸åï¼Œæ˜¯å› ç‚ºéº»å°‡çš„èµ·æºå’Œç™¼å±•èˆ‡ä¸­åœ‹çš„å‚³çµ±æ–‡åŒ–å’Œå“²å­¸æ€æƒ³æœ‰é—œã€‚\n",
      "\n",
      "åœ¨ä¸­åœ‹å¤ä»£ï¼Œæ±æ–¹è¢«è¦–ç‚ºé™½çš„æ–¹å‘ï¼Œä»£è¡¨è‘—å…‰æ˜å’Œç”Ÿé•·ï¼›è¥¿æ–¹è¢«è¦–ç‚ºé™°çš„æ–¹å‘ï¼Œä»£è¡¨è‘—é»‘æš—å’Œè¡°é€€ã€‚å› æ­¤ï¼Œåœ¨è¨±å¤šä¸­åœ‹å‚³çµ±çš„æ´»å‹•ä¸­ï¼Œæ±æ–¹è¢«è¦–ç‚ºå°Šè²´å’Œå‰ç¥¥çš„æ–¹å‘ã€‚\n",
      "\n",
      "åœ¨éº»å°‡ä¸­ï¼Œæ±æ–¹è¢«è¦–ç‚ºä¸»ä½ï¼Œä»£è¡¨è‘—ä¸»å®¶æˆ–èŠå®¶ã€‚ç‚ºäº†è¡¨ç¤ºå°Šé‡å’Œç¦®è²Œï¼Œå…¶ä»–ç©å®¶æœƒå°‡è‡ªå·±çš„åº§ä½å®‰æ’åœ¨æ±æ–¹çš„å°é¢ï¼Œå³è¥¿æ–¹ã€‚é€™æ¨£ä¸€ä¾†ï¼Œæ±æ–¹å°±æˆç‚ºäº†ä¸»ä½ï¼Œè¥¿æ–¹å°±æˆç‚ºäº†å®¢ä½ã€‚\n",
      "\n",
      "å—æ–¹å’ŒåŒ—æ–¹çš„å®‰æ’ä¹Ÿæ˜¯æ ¹æ“šä¸­åœ‹å‚³çµ±çš„å“²å­¸æ€æƒ³ã€‚å—æ–¹è¢«è¦–ç‚ºé™½çš„æ–¹å‘ï¼Œä»£è¡¨è‘—å…‰æ˜å’Œç”Ÿé•·ï¼›åŒ—æ–¹è¢«è¦–ç‚ºé™°çš„æ–¹å‘ï¼Œä»£è¡¨è‘—é»‘æš—å’Œè¡°é€€ã€‚å› æ­¤ï¼Œåœ¨éº»å°‡ä¸­ï¼Œå—æ–¹è¢«è¦–ç‚ºæ¬¡æ–¼æ±æ–¹çš„å°Šè²´æ–¹å‘ï¼ŒåŒ—æ–¹è¢«è¦–ç‚ºæœ€ä½çš„æ–¹å‘ã€‚\n",
      "\n",
      "é€™æ¨£çš„å®‰æ’æ–¹å¼ï¼Œå¯¦éš›ä¸Šæ˜¯å°‡å‚³çµ±çš„ä¸­åœ‹å“²å­¸æ€æƒ³å’Œæ–‡åŒ–è§€å¿µèå…¥åˆ°äº†éº»å°‡çš„è¦å‰‡ä¸­ã€‚é›–ç„¶é€™èˆ‡å¯¦éš›çš„æ–¹ä½ç›¸åï¼Œä½†å®ƒåæ˜ äº†ä¸­åœ‹å¤ä»£çš„æ–‡åŒ–å’Œå“²å­¸æ€æƒ³ã€‚\n",
      "å›ç­”: åœ¨éº»å°‡ä¸­ï¼Œå°æ•¸è¨ˆç®—èˆ‡æ±å—è¥¿åŒ—çš„å®‰æ’æœ‰é—œã€‚æ ¹æ“šéº»å°‡çš„è¦å‰‡ï¼ŒèŠå®¶ï¼ˆæ±æ–¹ï¼‰é€šå¸¸æœƒç²å¾—è¼ƒå¤šçš„å°æ•¸ï¼Œè€Œå®¢å®¶ï¼ˆè¥¿æ–¹ï¼‰å‰‡æœƒç²å¾—è¼ƒå°‘çš„å°æ•¸ã€‚\n",
      "\n",
      "åœ¨è¨ˆç®—å°æ•¸æ™‚ï¼ŒèŠå®¶é€šå¸¸æœƒç²å¾—ä»¥ä¸‹å°æ•¸ï¼š\n",
      "\n",
      "* æ±é¢¨ï¼š1å°\n",
      "* å—é¢¨ï¼š1å°\n",
      "* è‡ªé¢¨ï¼š1å°ï¼ˆå³èŠå®¶è‡ªå·±çš„é¢¨å‘ï¼‰\n",
      "\n",
      "è€Œå®¢å®¶å‰‡æœƒç²å¾—ä»¥ä¸‹å°æ•¸ï¼š\n",
      "\n",
      "* è¥¿é¢¨ï¼š0.5å°\n",
      "* åŒ—é¢¨ï¼š0.5å°\n",
      "* è‡ªé¢¨ï¼š0.5å°ï¼ˆå³å®¢å®¶çš„é¢¨å‘ï¼‰\n",
      "\n",
      "é€™æ¨£çš„å®‰æ’æ˜¯åŸºæ–¼ä¸­åœ‹å‚³çµ±çš„å“²å­¸æ€æƒ³å’Œæ–‡åŒ–è§€å¿µï¼ŒèŠå®¶è¢«è¦–ç‚ºä¸»ä½ï¼Œå®¢å®¶è¢«è¦–ç‚ºå®¢ä½ã€‚èŠå®¶ç²å¾—è¼ƒå¤šçš„å°æ•¸ï¼Œåæ˜ äº†ä¸»ä½çš„å°Šè²´å’Œé‡è¦æ€§ã€‚\n",
      "\n",
      "å¦å¤–ï¼Œåœ¨éº»å°‡ä¸­é‚„æœ‰ä¸€äº›ç‰¹æ®Šçš„å°æ•¸è¨ˆç®—ï¼Œä¾‹å¦‚ï¼š\n",
      "\n",
      "* ã€Œé–€æ¸…ã€ï¼šèŠå®¶åœ¨ç‰Œå±€é–‹å§‹æ™‚å°±èƒ½å¤ èƒ¡ç‰Œï¼Œç²å¾—3å°ã€‚\n",
      "* ã€Œè‡ªæ‘¸ã€ï¼šèŠå®¶æˆ–å®¢å®¶åœ¨ç‰Œå±€ä¸­è‡ªæ‘¸ç‰Œï¼Œç²å¾—2å°ã€‚\n",
      "* ã€Œæ¶èƒ¡ã€ï¼šèŠå®¶æˆ–å®¢å®¶æ¶èƒ¡ç‰Œï¼Œç²å¾—1å°ã€‚\n",
      "\n",
      "é€™äº›ç‰¹æ®Šçš„å°æ•¸è¨ˆç®—ä¹Ÿæ˜¯åŸºæ–¼ä¸­åœ‹å‚³çµ±çš„å“²å­¸æ€æƒ³å’Œæ–‡åŒ–è§€å¿µï¼Œåæ˜ äº†ç‰Œå±€ä¸­ä¸åŒæƒ…æ³ä¸‹çš„å°Šè²´å’Œé‡è¦æ€§ã€‚\n",
      "Assistant: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "# Create the Groq client\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "# Set the system prompt\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\":\n",
    "    \"ä½ æ˜¯å°ˆæ¥­çš„èªè¨€æ¨¡å‹ï¼Œå¯ä»¥å¹«åŠ©æˆ‘å›ç­”å•é¡Œï¼Œæä¾›ç¹é«”ä¸­æ–‡çš„å›ç­”\"\n",
    "}\n",
    "\n",
    "# Initialize the chat history\n",
    "chat_history = [system_prompt]\n",
    "\n",
    "while True:\n",
    "  # Get user input from the console\n",
    "  user_input = input(\"You: \")\n",
    "\n",
    "  # Exit the loop if the user enters \"exit\"\n",
    "  if user_input == \"exit\":\n",
    "    print(\"Assistant:\", \"Goodbye!\")\n",
    "    break\n",
    "\n",
    "  # Append the user input to the chat history\n",
    "  chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "  response = client.chat.completions.create(model=\"llama-3.1-70b-versatile\",\n",
    "                                            messages=chat_history,\n",
    "                                            max_tokens=1024,\n",
    "                                            temperature=0.3)\n",
    "  # Append the response to the chat history\n",
    "  chat_history.append({\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": response.choices[0].message.content\n",
    "  })\n",
    "  # Print the response\n",
    "  print(\"å›ç­”:\", response.choices[0].message.content)\n",
    "\n",
    "\n",
    "# ç¯„ä¾‹å•é¡Œ: éº»å°‡ä¸­çš„â€œæ±å—è¥¿åŒ—â€ç‚ºä»€éº¼å’Œå¯¦éš›æ–¹ä½ç›¸åå‘¢?\n",
    "# ç¯„ä¾‹å•é¡Œ: æœ‰ç”šéº¼éº»å°‡å°æ•¸è¨ˆç®—æ˜¯è·Ÿé€™æœ‰é—œçš„å‘¢?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
